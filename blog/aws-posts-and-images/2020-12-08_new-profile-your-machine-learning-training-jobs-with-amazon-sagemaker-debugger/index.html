<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  
  <!-- Primary Meta Tags -->
  <title>
<!-- Umami Analytics -->
<script defer src="https://cloud.umami.is/script.js" data-website-id="27550dad-d418-4f5d-ad1b-dab573da1020"></script>
<link rel="dns-prefetch" href="//cloud.umami.is">New – Profile Your Machine Learning Training Jobs With Amazon SageMaker Debugger - Julien Simon | AWS Expert</title>
  <meta name="title" content="New – Profile Your Machine Learning Training Jobs With Amazon SageMaker Debugger - Julien Simon | AWS Expert"/>
  <meta name="description" content="Expert analysis and technical deep-dive on new – profile your machine learning training jobs with amazon sagemaker debugger by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services."/>
  <meta name="keywords" content="AWS, Amazon Web Services, ['New', '–', 'Profile'], machine learning, AI, cloud computing, Julien Simon, AWS expert"/>
  <meta name="author" content="Julien Simon"/>
  <meta name="robots" content="index, follow"/>
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article"/>
  <meta property="og:url" content="https://julien.org/blog/new-profile-your-machine-learning-training-jobs-with-amazon-sagemaker-debugger/"/>
  <meta property="og:title" content="New – Profile Your Machine Learning Training Jobs With Amazon SageMaker Debugger - Julien Simon | AWS Expert"/>
  <meta property="og:description" content="Expert analysis and technical deep-dive on new – profile your machine learning training jobs with amazon sagemaker debugger by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services."/>
  <meta property="og:image" content="https://julien.org/assets/julien-simon-aws-expert.jpg"/>
  <meta property="og:site_name" content="Julien Simon - AWS Expert"/>
  <meta property="article:author" content="Julien Simon"/>
  <meta property="article:published_time" content="2020-12-08T00:00:00Z"/>
  <meta property="article:section" content="AWS"/>
  <meta property="article:tag" content="AWS, Amazon Web Services, Machine Learning, AI"/>
  
  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image"/>
  <meta property="twitter:url" content="https://julien.org/blog/new-profile-your-machine-learning-training-jobs-with-amazon-sagemaker-debugger/"/>
  <meta property="twitter:title" content="New – Profile Your Machine Learning Training Jobs With Amazon SageMaker Debugger - Julien Simon | AWS Expert"/>
  <meta property="twitter:description" content="Expert analysis and technical deep-dive on new – profile your machine learning training jobs with amazon sagemaker debugger by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services."/>
  <meta property="twitter:image" content="https://julien.org/assets/julien-simon-aws-expert.jpg"/>
  <meta property="twitter:creator" content="@julsimon"/>
  
  <!-- Canonical URL -->
  <link rel="canonical" href="https://julien.org/blog/new-profile-your-machine-learning-training-jobs-with-amazon-sagemaker-debugger/"/>
  
  <!-- Author and Publisher -->
  <link rel="author" href="https://julien.org/"/>
  <link rel="publisher" href="https://julien.org/"/>
  
  <!-- Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "New – Profile Your Machine Learning Training Jobs With Amazon SageMaker Debugger",
    "description": "Expert analysis and technical deep-dive on new – profile your machine learning training jobs with amazon sagemaker debugger by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services.",
    "image": "https://julien.org/assets/julien-simon-aws-expert.jpg",
    "author": {
      "@type": "Person",
      "name": "Julien Simon",
      "url": "https://julien.org/",
      "jobTitle": "AWS Expert & Former Global Technical Evangelist",
      "worksFor": {
        "@type": "Organization",
        "name": "Amazon Web Services"
      },
      "sameAs": [
        "https://twitter.com/julsimon",
        "https://linkedin.com/in/juliensimon",
        "https://github.com/juliensimon"
      ]
    },
    "publisher": {
      "@type": "Organization",
      "name": "Julien Simon",
      "url": "https://julien.org/",
      "logo": {
        "@type": "ImageObject",
        "url": "https://julien.org/assets/julien-simon-logo.jpg"
      }
    },
    "datePublished": "2020-12-08T00:00:00Z",
    "dateModified": "2020-12-08T00:00:00Z",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://julien.org/blog/new-profile-your-machine-learning-training-jobs-with-amazon-sagemaker-debugger/"
    },
    "url": "https://julien.org/blog/new-profile-your-machine-learning-training-jobs-with-amazon-sagemaker-debugger/",
    "keywords": "AWS, Amazon Web Services, ['New', '–', 'Profile'], machine learning, AI, cloud computing, Julien Simon, AWS expert",
    "articleSection": "AWS",
    "inLanguage": "en-US",
    "isPartOf": {
      "@type": "Blog",
      "name": "Julien Simon - AWS Expert Blog",
      "url": "https://julien.org/blog/"
    }
  }
  </script>
  
  <!-- Additional SEO Meta Tags -->
  <meta name="twitter:site" content="@julsimon"/>
  <meta name="twitter:creator" content="@julsimon"/>
  <meta name="theme-color" content="#FF9900"/>
  <meta name="msapplication-TileColor" content="#FF9900"/>
  <meta name="apple-mobile-web-app-capable" content="yes"/>
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>
  
  <!-- Preconnect to external domains -->
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="https://julien.org/favicon.ico"/>
  <link rel="apple-touch-icon" href="https://julien.org/apple-touch-icon.png"/>
  
  <style>
   body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        h1, h2, h3, h4, h5, h6 {
            color: #2c3e50;
            margin-top: 2em;
            margin-bottom: 0.5em;
        }
        h1 { font-size: 2.5em; }
        h2 { font-size: 2em; }
        h3 { font-size: 1.5em; }
        img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin: 1em 0;
        }
        /* Image alignment classes for text wraparound */
        img.alignleft {
            float: left;
            margin: 0.5em 1.5em 1em 0;
        }
        img.alignright {
            float: right;
            margin: 0.5em 0 1em 1.5em;
        }
        img.aligncenter {
            display: block;
            margin: 1em auto;
            float: none;
        }
        img.alignnone {
            float: none;
            margin: 1em 0;
        }
        /* Clear floats after images */
        .wp-block-image::after,
        p:has(img.alignleft)::after,
        p:has(img.alignright)::after {
            content: "";
            display: table;
            clear: both;
        }
        pre {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 1em;
            overflow-x: auto;
        }
        code {
            background: #f8f9fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: 'Monaco', 'Consolas', monospace;
        }
        blockquote {
            border-left: 4px solid #3498db;
            margin: 1em 0;
            padding-left: 1em;
            font-style: italic;
            color: #7f8c8d;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        p {
            margin-bottom: 1em;
        }
        .author-bio {
            background: #f8f9fa;
            border-left: 4px solid #FF9900;
            padding: 1em;
            margin: 2em 0;
            border-radius: 4px;
        }
        .author-bio h3 {
            margin-top: 0;
            color: #FF9900;
        }
        
  </style>
 </head>
 <body>
  <div style="margin-bottom: 1em;">
  <a href="../../../aws-blog-posts.html" style="color: #FF9900; text-decoration: none; font-size: 0.9em;">← Back to AWS Blog Posts</a>
</div>
  
  <h1>New – Profile Your Machine Learning Training Jobs With Amazon SageMaker Debugger</h1>
  
    
  
  <p style="color: #666; font-style: italic; margin-bottom: 1em;">
   Published: 2020-12-08 | Originally published at <a href="https://aws.amazon.com/blogs/aws/profile-your-machine-learning-training-jobs-with-amazon-sagemaker-debugger/" target="_blank" rel="noopener noreferrer">AWS Blog</a>
  </p>
 <body>
  <p>
   Today, I’m extremely happy to announce that
   <a href="https://aws.amazon.com/sagemaker/debugger">
    Amazon SageMaker Debugger
   </a>
   can now profile machine learning models, making it much easier to identify and fix training issues caused by hardware resource usage.
  </p>
  <p>
   Despite its impressive performance on a wide range of business problems, machine learning (ML) remains a bit of a mysterious topic. Getting things right is an alchemy of science, craftsmanship (some would say wizardry), and sometimes luck. In particular, model training is a complex process whose outcome depends on the quality of your dataset, your algorithm, its parameters, and the infrastructure you’re training on.
  </p>
  <p>
   As ML models become ever larger and more complex (I’m looking at you, deep learning), one growing issue is the amount of infrastructure required to train them. For instance, training
   <a href="https://arxiv.org/abs/1810.04805">
    BERT
   </a>
   on the publicly available
   <a href="https://cocodataset.org/">
    COCO
   </a>
   dataset takes well over six hours on a single
   <a href="https://aws.amazon.com/ec2/instance-types/p3/">
    <strong>
     p3dn.24xlarge
    </strong>
   </a>
   instance, even with its eight NVIDIA V100 GPUs. Some customers like autonomous vehicle companies deal with much larger datasets, and train object detection models for several days.
  </p>
  <p>
   When a complex training job takes this long, the odds that something goes wrong and ruins it are pretty high, not only wasting time and money but also causing lots of frustration. Important work needs to be put on the back burner while you investigate, figure out the root cause, try to fix it, and then run your training job again. Often, you’ll have to iterate quite a few times to nail the problem.
  </p>
  <p>
   Depending on the ML framework that you use, and sometimes on its version, you may or may not be able to use existing framework-specific tools. Often, you’ll have to build and maintain your own bespoke tools. Even for experienced practitioners, this is a lot of hard work. For regular developers like me, this is an utterly daunting task.
  </p>
  <p>
   <strong>
    <span style="text-decoration: underline;">
     Introducing Model Profiling in Amazon SageMaker Debugger
    </span>
   </strong>
   <br/>
   <a href="https://aws.amazon.com/blogs/aws/amazon-sagemaker-debugger-debug-your-machine-learning-models/">
    Launched
   </a>
   last year at AWS re:Invent,
   <a href="https://aws.amazon.com/sagemaker/debugger">
    Amazon SageMaker Debugger
   </a>
   is a capability of
   <a href="https://aws.amazon.com/sagemaker/">
    Amazon SageMaker
   </a>
   that automatically identifies complex
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.html">
    issues
   </a>
   developing in ML training jobs. These include loss not decreasing, exploding gradients, and more.
  </p>
  <p>
   Now,
   <span title="Amazon SageMaker Debugger">
    SageMaker Debugger
   </span>
   can also monitor hardware resource usage, and allows you to profile your training job to help you correlate resource usage to ML operations in your training script. Thus, you’ll be able to resolve performance issues much quicker, and iterate through your training job much faster.
  </p>
  <p style="padding-left: 40px;">
   <a href="https://www.linkedin.com/in/chaim-rand-7692721/">
    Chaim Rand
   </a>
   , ML Algorithm Developer at
   <a href="https://www.mobileye.com/">
    Mobileye
   </a>
   , an Intel company building automated driving and driver assistance systems, had the opportunity to work with the new profiling capabilities, and here’s what he told us: “
   <em>
    Many of the assisted driving and autonomous vehicle technologies that we develop at Mobileye, rely on training deep neural network models to detect a wide variety of road artifacts, including vehicles, pedestrians, speed bumps, road signs and more. Often, these models train on extremely large datasets, on multiple machines, and for periods of up to several days. For us, at Mobileye, it is imperative that we have a toolkit of advanced performance profiling capabilities, for analyzing the flow of data across the network, CPU, and GPU resources, and for pinpointing performance issues. The profiling functionality in SageMaker Debugger provides just that, taking performance profiling out of the domain of a few specialized experts, and empowering our algorithm developers to maximize training resource utilization, accelerate model convergence, and reduce cost.
   </em>
   ”
  </p>
  <p>
   At launch, the new profiling capability of
   <span title="Amazon SageMaker Debugger">
    SageMaker Debugger
   </span>
   is available for TensorFlow 2.x and PyTorch 1.x. All you have to do is to train with the corresponding
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/frameworks.html">
    built-in frameworks
   </a>
   in
   <a href="https://aws.amazon.com/sagemaker/">
    Amazon SageMaker
   </a>
   . Distributed training is supported out of the box.
  </p>
  <p>
   Setting a single parameter in your SageMaker estimator, and without any change to your training code, you can enable the collection of infrastructure and model metrics such as:
  </p>
  <ul>
   <li>
    CPU and GPU,
   </li>
   <li>
    RAM and GPU RAM,
   </li>
   <li>
    Network I/O,
   </li>
   <li>
    Storage I/O (local storage and Pipe Mode),
   </li>
   <li>
    Python metrics,
   </li>
   <li>
    Data loading time,
   </li>
   <li>
    Time spent in ML operators running on CPU and GPU,
   </li>
   <li>
    Distributed training metrics for
    <a href="https://github.com/horovod/horovod">
     Horovod
    </a>
    ,
   </li>
   <li>
    and many more.
   </li>
  </ul>
  <p>
   In addition, you can visualize how much time is spent in different phases, such as preprocessing, training loop, and postprocessing. If needed, you can drill down on each training epoch, and even on each function in your training script.
  </p>
  <p>
   By default, metrics are collected every 500ms, and you can also set this value to 100ms, 200ms, 1s, 5s, and 1min. For finer-grained analysis, you can also enable and disable profiling explicitly in your training code, only capturing metrics for specific parts.
  </p>
  <p>
   While your training job is running, you can easily visualize these metrics in Amazon SageMaker Studio, our web-based integrated development environment for ML. As you would expect, all data is also available through the
   <span title="Amazon SageMaker Debugger">
    SageMaker Debugger
   </span>
   API, and you can retrieve it to build your own graphs.
  </p>
  <p>
   Running in parallel of the training job, an
   <a href="https://aws.amazon.com/sagemaker/">
    Amazon SageMaker Processing
   </a>
   analyzes captured data, builds graphs, and generates a report providing insights on potential problems. This doesn’t require any work on your part, as this analysis runs inside a built-in container on fully managed infrastructure.
  </p>
  <p>
   Now, let’s run a demo with PyTorch, where we’ll profile a ResNet-50 image classification model training on the CIFAR-10 dataset.
  </p>
  <p>
   <strong>
    <span style="text-decoration: underline;">
     Profiling a Training Job with Amazon SageMaker Debugger
     <br/>
    </span>
   </strong>
   All it takes to enable profiling on your training job is an extra parameter in your SageMaker estimator. You don’t need to change a line in your training code. By default,
   <span title="Amazon SageMaker Debugger">
    SageMaker Debugger
   </span>
   uses a set of built-in profiling rules looking for unwanted conditions that could develop during training, such as low GPU utilization. On top of reporting these conditions,
   <span title="Amazon SageMaker Debugger">
    SageMaker Debugger
   </span>
   also triggers events in
   <a href="https://aws.amazon.com/blogs/aws/new-cloudwatch-events-track-and-respond-to-changes-to-your-aws-resources/">
    CloudWatch Events
   </a>
   . For example, I could use them to run a
   <a href="https://aws.amazon.com/lambda/">
    AWS Lambda
   </a>
   function that automatically stops inefficient training jobs.
  </p>
  <p>
   First, I create a profiling configuration capturing data every 500ms. Optionally, I could select a training step interval if I wanted to profile only a certain portion of the job.
  </p>
  <pre><code class="lang-python">import sagemaker
from sagemaker.profiler import ProfilerConfig 
profiler_config = ProfilerConfig(profiling_interval_millis=500)</code></pre>
  <p>
   Then, I pass this configuration to my PyTorch
   <a href="https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html">
    <code>
     Estimator
    </code>
   </a>
   , training on an
   <strong>
    ml.p3.8xlarge
   </strong>
   instance equipped with 4 NVIDIA V100 GPUs.
  </p>
  <pre><code class="lang-python">from sagemaker.pytorch import PyTorch
estimator = PyTorch(
    role=sagemaker.get_execution_role(),
    instance_count=1,
    instance_type='ml.p3.8xlarge',
    entry_point='train_pt.py',
    framework_version='1.5.0',
    hyperparameters={"batch_size":512, "epochs":10},
    profiler_config=profiler_config)</code></pre>
  <p>
   Then, I launch the training job as usual. Once the job is running, profiling data is captured and stored in Amazon S3.
  </p>
  <pre><code class="lang-python">path = estimator.latest_job_profiler_artifacts_path()
print(path)
s3://sagemaker-us-east-2-123456789012/pt-train-pt-2020-11-17-17-38-43-231/profiler-output</code></pre>
  <p>
   Using the SageMaker SDK, I can retrieve and count profiling events.
  </p>
  <pre><code class="lang-python">from smdebug.profiler.system_metrics_reader import S3SystemMetricsReader
system_metrics_reader = S3SystemMetricsReader(path)
system_metrics_reader.refresh_event_file_list()
last_timestamp = system_metrics_reader.get_timestamp_of_latest_available_file()
events = system_metrics_reader.get_events(0, last_timestamp)
print("Found", len(events), "recorded system metric events. Latest recorded event:", last_timestamp)
Found 411853 recorded system metric events. Latest recorded event: 1605620280000000</code></pre>
  <p>
   Of course, I could parse and analyze these profiling events, build my own graphs, and so on. Instead, let’s visualize them in near real-time in SageMaker Studio.
  </p>
  <p>
   While my training job is still running, I locate it in SageMaker Studio, and I right-click “Open Debugger for insights”.
  </p>
  <p>
   <img alt="SageMaker screenshot" class="aligncenter wp-image-44150 size-full" height="183" src="image01.webp" width="796"/>
  </p>
  <p>
   This opens a new tab, and I select the “Nodes” panel where I can see details statistics for each instance in my training job. So, how’s my training job doing? Feel free to click on the image below to zoom in.
  </p>
  <p>
   <a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2020/11/25/Capture-d’écran-2020-11-25-à-16.24.03.png">
    <img alt="SageMaker screenshot" class="aligncenter wp-image-44152 size-large" height="359" loading="lazy" src="image02.webp" width="1024"/>
   </a>
  </p>
  <p>
   Apparently, this job isn’t going great. GPU utilization and GPU memory utilization are desperately flat at around 10%. I’m definitely not pushing my multi-GPU instance hard enough. Maybe GPUs are not receiving data fast enough because the CPU can’t keep up? Let’s check the system utilization heatmap.
  </p>
  <p>
   <a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2020/11/25/Capture-d’écran-2020-11-25-à-16.24.13.png">
    <img alt="SageMaker screenshot" class="aligncenter wp-image-44154 size-large" height="276" loading="lazy" src="image03.webp" width="1024"/>
   </a>
  </p>
  <p>
   The CPU is taking a nap here, hardly ever exceeding 20% usage. This instance is definitely not busy enough. Is there anything I could do to fix this?
  </p>
  <p>
   Switching to the “Overview” panel, I see that some of the built-in profiling rules have been triggered.
  </p>
  <p>
   <img alt="SageMaker screenshot" class="aligncenter wp-image-44155 size-full" height="189" loading="lazy" src="image04.webp" width="448"/>
  </p>
  <p>
   <code>
    LowGPUUtilization
   </code>
   confirms what I saw on the graphs above.
   <code>
    BatchSize
   </code>
   is very interesting, as it suggests increasing the size of mini-batches sent to the GPUs by the training script running on the CPU. This should definitely help fill GPU memory, put more GPU cores to work, speed up my training job, and improve infrastructure usage.
  </p>
  <p>
   At this point, I should decide to stop my inefficient training job, and to relaunch it with a larger batch size. Here, I’ll let it run to completion to show you the report generated by the
   <span title="Amazon SageMaker Processing">
    SageMaker Processing
   </span>
   job running in parallel of your training job.
  </p>
  <p>
   Once the training job is complete, I can see its summary in the “Overview” panel.
  </p>
  <p>
   <img alt="SageMaker screenshot" class="wp-image-44157 size-full aligncenter" height="824" loading="lazy" src="image05.webp" width="713"/>
  </p>
  <p>
   Clicking on the “Download report” button, I get a very detailed report that includes additional metrics, for example the ratio between the different phases of the training job, or the ratio between the forward and backward pass.
  </p>
  <p>
   <a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2020/11/25/Capture-d’écran-2020-11-25-à-17.13.53.png">
    <img alt="SageMaker screenshot" class="aligncenter wp-image-44158 size-large" height="708" loading="lazy" src="image06.webp" style="border: 1px solid black;" width="1024"/>
   </a>
  </p>
  <p>
   I can also see information on the most time-consuming CPU and GPU operators, which is really important if I wanted to optimize my code. For example, the graph below tells me that the most time-consuming GPU operations in my training job are backward pass convolution operators.
  </p>
  <p>
   <a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2020/11/25/Capture-d’écran-2020-11-25-à-17.17.39.png">
    <img alt="SageMaker screenshot" class="aligncenter wp-image-44159 size-large" height="401" loading="lazy" src="image07.webp" style="border: 1px solid black;" width="1024"/>
   </a>
  </p>
  <p>
   There’s much more to read in the report (rules summary, training loop analysis, and more). A companion notebook is also available to understand how graphs have been built, and how you can tailor them to your own needs.
  </p>
  <p>
   <span style="text-decoration: underline;">
    <strong>
     Getting Started
     <br/>
    </strong>
   </span>
   We’ve just scratched the surface, and there are many more features in
   <a href="https://aws.amazon.com/sagemaker/debugger">
    Amazon SageMaker Debugger
   </a>
   that make it easy to gather, analyze and visualize model profiling information. You can start using it today in all regions where Amazon SageMaker is available. You won’t be charged for any compute used to run built-in profiling rules.
  </p>
  <p>
   You’ll find
   <a href="https://github.com/aws/amazon-sagemaker-examples">
    sample notebooks
   </a>
   on Github, so
   <a href="https://console.aws.amazon.com/sagemaker">
    give them a try
   </a>
   , and let us know what you think. We’re always looking forward to your feedback, either through your usual AWS support contacts, or on the
   <a href="https://forums.aws.amazon.com/forum.jspa?forumID=285">
    AWS Forum
   </a>
   for SageMaker.
  </p>
  <a href="https://aws.amazon.com/developer/community/evangelists/julien-simon/">
   - Julien
  </a>
  <!-- '"` -->
  <hr/>
  <h3>
   About the Author
  </h3>
  <p>
   <strong>
    Julien is the Artificial Intelligence &amp; Machine Learning Evangelist for EMEA
   </strong>
   . He focuses on helping developers and enterprises bring their ideas to life. In his spare time, he reads the works of JRR Tolkien again and again.
  </p>
  <p>
  </p>
  <p>
  </p>
  <p>
  </p>
  <!-- '"` -->
 
  
  </body>
 </html>
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  
  <!-- Primary Meta Tags -->
  <title>New – Label Videos with Amazon SageMaker Ground Truth - Julien Simon | AWS Expert</title>
  <meta name="title" content="New – Label Videos with Amazon SageMaker Ground Truth - Julien Simon | AWS Expert"/>
  <meta name="description" content="Expert analysis and technical deep-dive on new – label videos with amazon sagemaker ground truth by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services."/>
  <meta name="keywords" content="AWS, Amazon Web Services, ['New', '–', 'Label'], machine learning, AI, cloud computing, Julien Simon, AWS expert"/>
  <meta name="author" content="Julien Simon"/>
  <meta name="robots" content="index, follow"/>
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article"/>
  <meta property="og:url" content="https://julien.org/blog/new-label-videos-with-amazon-sagemaker-ground-truth/"/>
  <meta property="og:title" content="New – Label Videos with Amazon SageMaker Ground Truth - Julien Simon | AWS Expert"/>
  <meta property="og:description" content="Expert analysis and technical deep-dive on new – label videos with amazon sagemaker ground truth by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services."/>
  <meta property="og:image" content="https://julien.org/assets/julien-simon-aws-expert.jpg"/>
  <meta property="og:site_name" content="Julien Simon - AWS Expert"/>
  <meta property="article:author" content="Julien Simon"/>
  <meta property="article:published_time" content="2020-07-09T00:00:00Z"/>
  <meta property="article:section" content="AWS"/>
  <meta property="article:tag" content="AWS, Amazon Web Services, Machine Learning, AI"/>
  
  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image"/>
  <meta property="twitter:url" content="https://julien.org/blog/new-label-videos-with-amazon-sagemaker-ground-truth/"/>
  <meta property="twitter:title" content="New – Label Videos with Amazon SageMaker Ground Truth - Julien Simon | AWS Expert"/>
  <meta property="twitter:description" content="Expert analysis and technical deep-dive on new – label videos with amazon sagemaker ground truth by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services."/>
  <meta property="twitter:image" content="https://julien.org/assets/julien-simon-aws-expert.jpg"/>
  <meta property="twitter:creator" content="@julsimon"/>
  
  <!-- Canonical URL -->
  <link rel="canonical" href="https://julien.org/blog/new-label-videos-with-amazon-sagemaker-ground-truth/"/>
  
  <!-- Author and Publisher -->
  <link rel="author" href="https://julien.org/"/>
  <link rel="publisher" href="https://julien.org/"/>
  
  <!-- Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "New – Label Videos with Amazon SageMaker Ground Truth",
    "description": "Expert analysis and technical deep-dive on new – label videos with amazon sagemaker ground truth by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services.",
    "image": "https://julien.org/assets/julien-simon-aws-expert.jpg",
    "author": {
      "@type": "Person",
      "name": "Julien Simon",
      "url": "https://julien.org/",
      "jobTitle": "AWS Expert & Former Global Technical Evangelist",
      "worksFor": {
        "@type": "Organization",
        "name": "Amazon Web Services"
      },
      "sameAs": [
        "https://twitter.com/julsimon",
        "https://linkedin.com/in/juliensimon",
        "https://github.com/juliensimon"
      ]
    },
    "publisher": {
      "@type": "Organization",
      "name": "Julien Simon",
      "url": "https://julien.org/",
      "logo": {
        "@type": "ImageObject",
        "url": "https://julien.org/assets/julien-simon-logo.jpg"
      }
    },
    "datePublished": "2020-07-09T00:00:00Z",
    "dateModified": "2020-07-09T00:00:00Z",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://julien.org/blog/new-label-videos-with-amazon-sagemaker-ground-truth/"
    },
    "url": "https://julien.org/blog/new-label-videos-with-amazon-sagemaker-ground-truth/",
    "keywords": "AWS, Amazon Web Services, ['New', '–', 'Label'], machine learning, AI, cloud computing, Julien Simon, AWS expert",
    "articleSection": "AWS",
    "inLanguage": "en-US",
    "isPartOf": {
      "@type": "Blog",
      "name": "Julien Simon - AWS Expert Blog",
      "url": "https://julien.org/blog/"
    }
  }
  </script>
  
  <!-- Additional SEO Meta Tags -->
  <meta name="twitter:site" content="@julsimon"/>
  <meta name="twitter:creator" content="@julsimon"/>
  <meta name="theme-color" content="#FF9900"/>
  <meta name="msapplication-TileColor" content="#FF9900"/>
  <meta name="apple-mobile-web-app-capable" content="yes"/>
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>
  
  <!-- Preconnect to external domains -->
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="https://julien.org/favicon.ico"/>
  <link rel="apple-touch-icon" href="https://julien.org/apple-touch-icon.png"/>
  
  <style>
   body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        h1, h2, h3, h4, h5, h6 {
            color: #2c3e50;
            margin-top: 2em;
            margin-bottom: 0.5em;
        }
        h1 { font-size: 2.5em; }
        h2 { font-size: 2em; }
        h3 { font-size: 1.5em; }
        img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin: 1em 0;
        }
        /* Image alignment classes for text wraparound */
        img.alignleft {
            float: left;
            margin: 0.5em 1.5em 1em 0;
        }
        img.alignright {
            float: right;
            margin: 0.5em 0 1em 1.5em;
        }
        img.aligncenter {
            display: block;
            margin: 1em auto;
            float: none;
        }
        img.alignnone {
            float: none;
            margin: 1em 0;
        }
        /* Clear floats after images */
        .wp-block-image::after,
        p:has(img.alignleft)::after,
        p:has(img.alignright)::after {
            content: "";
            display: table;
            clear: both;
        }
        pre {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 1em;
            overflow-x: auto;
        }
        code {
            background: #f8f9fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: 'Monaco', 'Consolas', monospace;
        }
        blockquote {
            border-left: 4px solid #3498db;
            margin: 1em 0;
            padding-left: 1em;
            font-style: italic;
            color: #7f8c8d;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        p {
            margin-bottom: 1em;
        }
        .author-bio {
            background: #f8f9fa;
            border-left: 4px solid #FF9900;
            padding: 1em;
            margin: 2em 0;
            border-radius: 4px;
        }
        .author-bio h3 {
            margin-top: 0;
            color: #FF9900;
        }
        
  </style>
 </head>
 <body>
  <div style="margin-bottom: 1em;">
  <a href="../../../aws-blog-posts.html" style="color: #FF9900; text-decoration: none; font-size: 0.9em;">← Back to AWS Blog Posts</a>
</div>
  
  <h1>New – Label Videos with Amazon SageMaker Ground Truth</h1>
  
    
  
  <p style="color: #666; font-style: italic; margin-bottom: 1em;">
   Published: 2020-07-09 | Originally published at <a href="https://aws.amazon.com/blogs/aws/new-label-videos-with-amazon-sagemaker-ground-truth/" target="_blank" rel="noopener noreferrer">AWS Blog</a>
  </p>
 <body>
  <p>
   <a href="https://aws.amazon.com/blogs/aws/amazon-sagemaker-ground-truth-build-highly-accurate-datasets-and-reduce-labeling-costs-by-up-to-70/">
    Launched
   </a>
   at AWS re:Invent 2018,
   <a href="https://aws.amazon.com/sagemaker/groundtruth/">
    Amazon Sagemaker Ground Truth
   </a>
   is a capability of
   <a href="https://aws.amazon.com/sagemaker/">
    Amazon SageMaker
   </a>
   that makes it easy to annotate machine learning datasets.
   <a href="https://aws.amazon.com/sagemaker/groundtruth/customers/">
    Customers
   </a>
   can efficiently and accurately label image, text and
   <a href="https://aws.amazon.com/blogs/aws/new-label-3d-point-clouds-with-amazon-sagemaker-ground-truth/">
    3D point cloud
   </a>
   data with
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-task-types.html">
    built-in workflows
   </a>
   , or any other type of data with
   <a href="https://aws.amazon.com/blogs/machine-learning/build-a-custom-data-labeling-workflow-with-amazon-sagemaker-ground-truth/">
    custom workflows
   </a>
   . Data samples are automatically distributed to a workforce (private, 3rd party or
   <a href="https://www.mturk.com/">
    MTurk
   </a>
   ), and annotations are stored in
   <a href="https://aws.amazon.com/s3/">
    Amazon Simple Storage Service (Amazon S3)
   </a>
   . Optionally,
   <a href="https://aws.amazon.com/blogs/machine-learning/annotate-data-for-less-with-amazon-sagemaker-ground-truth-and-automated-data-labeling/">
    automated data labeling
   </a>
   may also be enabled, reducing both the amount of time required to label the dataset, and the associated costs.
  </p>
  <p>
   As models become more sophisticated, AWS customers are increasingly applying machine learning prediction to video content.
   <a href="https://aws.amazon.com/automotive/autonomous-driving/">
    Autonomous driving
   </a>
   is perhaps the most well-known use case, as safety demands that road condition and moving objects be correctly detected and tracked in real-time. Video prediction is also a popular application in
   <a href="https://aws.amazon.com/sports/">
    Sports
   </a>
   , tracking players or racing vehicles to compute all kinds of statistics that fans are so fond of.
   <a href="https://aws.amazon.com/health/">
    Healthcare
   </a>
   organizations also use video prediction to identify and track anatomical objects in medical videos.
   <a href="https://aws.amazon.com/manufacturing/">
    Manufacturing
   </a>
   companies do the same to track objects on the assembly line, parcels for logistics, and more. The list goes on, and amazing applications keep popping up in many different industries.
  </p>
  <p>
   Of course, this requires building and labeling video datasets, where objects of interest need to be labeled manually. At 30 frames per second, one minute of video translates to 1,800 individual images, so the amount of work can quickly become overwhelming. In addition, specific tools have to be built to label images, manage workflows, and so on. All this work takes valuable time and resources away from an organization’s core business.
  </p>
  <p>
   AWS customers have asked us for a better solution, and today I’m very happy to announce that
   <a href="https://aws.amazon.com/sagemaker/groundtruth/">
    Amazon Sagemaker Ground Truth
   </a>
   now supports video labeling.
  </p>
  <p>
   <strong>
    <span style="text-decoration: underline;">
     Customer use case: the National Football League
    </span>
   </strong>
   <br/>
   The
   <a href="https://aws.amazon.com/nfl/">
    National Football League
   </a>
   (NFL) has already put this new feature to work. Says Jennifer Langton, SVP of Player Health and Innovation, NFL: “
   <em>
    At the National Football League (NFL), we continue to look for new ways to use machine learning (ML) to help our fans, broadcasters, coaches, and teams benefit from deeper insights. Building these capabilities requires large amounts of accurately labeled training data. Amazon SageMaker Ground Truth was truly a force multiplier in accelerating our project timelines. We leveraged the new video object tracking workflow in addition to other existing computer vision (CV) labeling workflows to develop labels for training a computer vision system that tracks all 22 players as they move on the field during plays. Amazon SageMaker Ground Truth reduced the timeline for developing a high quality labeling dataset by more than 80%
   </em>
   ”.
  </p>
  <p>
   Courtesy of the
   <a href="https://www.nfl.com">
    NFL
   </a>
   , here are a couple of predicted frames, showing helmet detection in a
   <a href="https://www.seahawks.com/">
    Seattle Seahawks
   </a>
   video. This particular video has 353 frames. This first picture is frame #100.
  </p>
  <p>
   <a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2020/07/09/Seahawks-Screenshot-1.png">
    <img alt="Object tracking" class="size-large wp-image-38878 aligncenter" height="932" src="image01.webp" style="border: 1px solid black;" width="1024"/>
   </a>
  </p>
  <p>
   This second picture is frame #110.
  </p>
  <p>
   <a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2020/07/09/Seahawks-Screenshot-2.png">
    <img alt="Object tracking" class="wp-image-38879 size-large aligncenter" height="946" loading="lazy" src="image02.webp" style="border: 1px solid black;" width="1024"/>
   </a>
  </p>
  <p>
   <span style="text-decoration: underline;">
    <strong>
     Introducing Video Labeling
     <br/>
    </strong>
   </span>
   With the addition of video task types, customers can now use
   <a href="https://aws.amazon.com/sagemaker/groundtruth/">
    Amazon Sagemaker Ground Truth
   </a>
   for:
  </p>
  <ul>
   <li>
    Video clip classification
   </li>
   <li>
    Video multi-frame object detection
   </li>
   <li>
    Video multi-frame object tracking
   </li>
  </ul>
  <p>
   The multi-frame task types support multiple labels, so that you may label different object classes present in the video frames. You can create labeling jobs to annotate frames from scratch, as well as adjustment jobs to review and fine tune frames that have already been labeled. These jobs may be distributed either to a private workforce, or to a vendor workforce you picked on
   <a href="https://aws.amazon.com/marketplace/search/results?page=1&amp;searchTerms=labeling&amp;category=83fb9ade-65b6-45bc-bd9d-0a3db0b6994c">
    AWS Marketplace
   </a>
   .
  </p>
  <p>
   Using the built-in GUI, workers can then easily label and track objects across frames. Once they’ve annotated a frame, they can use an assistive labeling feature to predict the location of bounding boxes in the next frame, as you will see in the demo below. This significantly simplifies labeling work, saves time, and improves the quality of annotations. Last but not least, work is saved automatically.
  </p>
  <p>
   <strong>
    <span style="text-decoration: underline;">
     Preparing Input Data for Video Object Detection and Tracking
     <br/>
    </span>
   </strong>
   As you would expect, input data must be located in S3. You may bring either video files, or sequences of video frames.
  </p>
  <p>
   The first option is the simplest, as
   <a href="https://aws.amazon.com/sagemaker/groundtruth/">
    Amazon Sagemaker Ground Truth
   </a>
   includes a tool that automatically extracts frames from your video files. Optionally, you can sample frames (1 in ‘n’), in order to reduce the amount of labeling work. The extraction tool also builds a manifest file describing sequences and frames. You can learn more about it in the
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-point-cloud-video-input-data.html#sms-point-cloud-video-frame-extraction">
    documentation
   </a>
   .
  </p>
  <p>
   The second option requires two steps: extracting frames, and building the manifest file. Extracting frames can easily be performed with the popular
   <em>
    <a href="https://ffmpeg.org/">
     ffmpeg
    </a>
   </em>
   open source tool. Here’s how you could convert the first 60 seconds of a video to a frame sequence.
  </p>
  <p>
   <code>
    $ ffmpeg -ss 00:00:00.00 -t 00:01:0.00 -i basketball.mp4 frame%04d.jpg
   </code>
  </p>
  <p>
   Each frame sequence should be uploaded to S3 under a different prefix, for example
   <code>
    s3://my-bucket/my-videos/sequence1
   </code>
   ,
   <code>
    s3://my-bucket/my-videos/sequence2
   </code>
   , and so on, as explained in the
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-point-cloud-video-input-data.html#sms-video-provide-frames">
    documentation
   </a>
   .
  </p>
  <p>
   Once you have uploaded your frame sequences, you may then either bring your own JSON files to describe them, or let
   <span title="Amazon Sagemaker Ground Truth">
    Ground Truth
   </span>
   crawl your sequences and build the JSON files and the manifest file for you automatically. Please note that a video sequence cannot be longer than 2,000 frames, which corresponds to about a minute of video at 30 frames per second.
  </p>
  <p>
   Each sequence should be described by a simple sequence file:
  </p>
  <ul>
   <li>
    A sequence number, an S3 prefix, and a number of frames.
   </li>
   <li>
    A list of frames: number, file name, and creation timestamp.
   </li>
  </ul>
  <p>
   Here’s an example of a sequence file.
  </p>
  <div class="hide-language">
   <pre><code class="lang-json">{"version": "2020-06-01",
"seq-no": 1, "prefix": "s3://jsimon-smgt/videos/basketball", "number-of-frames": 1800, 
	"frames": [
		{"frame-no": 1, "frame": "frame0001.jpg", "unix-timestamp": 1594111541.71155},
		{"frame-no": 2, "frame": "frame0002.jpg", "unix-timestamp": 1594111541.711552},
		{"frame-no": 3, "frame": "frame0003.jpg", "unix-timestamp": 1594111541.711553},
		{"frame-no": 4, "frame": "frame0004.jpg", "unix-timestamp": 1594111541.711555},
. . .</code></pre>
  </div>
  <p>
   Finally, the manifest file should point at the sequence files you’d like to include in the labeling job. Here’s an example.
  </p>
  <p>
   <code>
    {"source-ref": "s3://jsimon-smgt/videos/seq1.json"}
   </code>
   <br/>
   <code>
    {"source-ref": "s3://jsimon-smgt/videos/seq2.json"}
    <br/>
    . . .
   </code>
  </p>
  <p>
   Just like for other task types, the augmented manifest is available in S3 once labeling is complete. It contains annotations and labels, which you can then feed to your machine learning training job.
  </p>
  <p>
   <strong>
    <span style="text-decoration: underline;">
     Labeling Videos with Amazon SageMaker Ground Truth
     <br/>
    </span>
   </strong>
   Here’s a
   <a href="https://youtu.be/UZBL4jgTpOs">
    sample video
   </a>
   where I label the first ten frames of a sequence. You can see a screenshot below.
  </p>
  <p>
   <a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2020/07/03/Capture-d’écran-2020-07-03-à-18.10.34.png">
    <img alt="" class="size-large wp-image-38777 aligncenter" height="550" loading="lazy" src="image03.webp" style="border: 1px solid black;" width="1024"/>
   </a>
  </p>
  <p>
   I first use the
   <span title="Amazon Sagemaker Ground Truth">
    Ground Truth
   </span>
   GUI to carefully label the first frame, drawing bounding boxes for basketballs and basketball players. Then, I use the “Predict next” assistive labeling tool to predict the location of the boxes in the next nine frames, applying only minor adjustments to some boxes. Although this was my first try, I found the process easy and intuitive. With a little practice, I could certainly go much faster!
  </p>
  <p>
   <span style="text-decoration: underline;">
    <strong>
     Getting Started
    </strong>
   </span>
   <br/>
   Now, it’s your turn. You can start labeling videos with
   <a href="https://aws.amazon.com/sagemaker/groundtruth/">
    Amazon Sagemaker Ground Truth
   </a>
   today in the following regions:
  </p>
  <ul>
   <li>
    US East (N. Virginia), US East (Ohio), US West (Oregon),
   </li>
   <li>
    Canada (Central),
   </li>
   <li>
    Europe (Ireland), Europe (London), Europe (Frankfurt),
   </li>
   <li>
    Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Seoul), Asia Pacific (Sydney), Asia Pacific (Tokyo).
   </li>
  </ul>
  <p>
   We’re looking forward to reading your feedback. You can send it through your usual support contacts, or in the
   <a href="https://forums.aws.amazon.com/forum.jspa?forumID=285">
    AWS Forum
   </a>
   for
   <a href="https://aws.amazon.com/sagemaker/">
    Amazon SageMaker
   </a>
   .
  </p>
  <a href="https://aws.amazon.com/developer/community/evangelists/julien-simon/">
   - Julien
  </a>
  <!-- '"` -->
  <hr/>
  <h3>
   About the Author
  </h3>
  <p>
   <strong>
    Julien is the Artificial Intelligence &amp; Machine Learning Evangelist for EMEA
   </strong>
   . He focuses on helping developers and enterprises bring their ideas to life. In his spare time, he reads the works of JRR Tolkien again and again.
  </p>
  <p>
  </p>
  <p>
  </p>
  <p>
  </p>
  <!-- '"` -->
 
  
  </body>
 </html>
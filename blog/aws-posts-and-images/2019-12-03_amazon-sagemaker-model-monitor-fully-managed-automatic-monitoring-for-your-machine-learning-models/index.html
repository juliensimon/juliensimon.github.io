<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  
  <!-- Primary Meta Tags -->
  <title>Amazon SageMaker Model Monitor – Fully Managed Automatic Monitoring For Your Machine Learning Models - Julien Simon | AWS Expert</title>
  <meta name="title" content="Amazon SageMaker Model Monitor – Fully Managed Automatic Monitoring For Your Machine Learning Models - Julien Simon | AWS Expert"/>
  <meta name="description" content="Expert analysis and technical deep-dive on amazon sagemaker model monitor – fully managed automatic monitoring for your machine learning models by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services."/>
  <meta name="keywords" content="AWS, Amazon Web Services, ['Amazon', 'SageMaker', 'Model'], machine learning, AI, cloud computing, Julien Simon, AWS expert"/>
  <meta name="author" content="Julien Simon"/>
  <meta name="robots" content="index, follow"/>
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article"/>
  <meta property="og:url" content="https://julien.org/blog/amazon-sagemaker-model-monitor-fully-managed-automatic-monitoring-for-your-machine-learning-models/"/>
  <meta property="og:title" content="Amazon SageMaker Model Monitor – Fully Managed Automatic Monitoring For Your Machine Learning Models - Julien Simon | AWS Expert"/>
  <meta property="og:description" content="Expert analysis and technical deep-dive on amazon sagemaker model monitor – fully managed automatic monitoring for your machine learning models by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services."/>
  <meta property="og:image" content="https://julien.org/assets/julien-simon-aws-expert.jpg"/>
  <meta property="og:site_name" content="Julien Simon - AWS Expert"/>
  <meta property="article:author" content="Julien Simon"/>
  <meta property="article:published_time" content="2019-12-03T00:00:00Z"/>
  <meta property="article:section" content="AWS"/>
  <meta property="article:tag" content="AWS, Amazon Web Services, Machine Learning, AI"/>
  
  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image"/>
  <meta property="twitter:url" content="https://julien.org/blog/amazon-sagemaker-model-monitor-fully-managed-automatic-monitoring-for-your-machine-learning-models/"/>
  <meta property="twitter:title" content="Amazon SageMaker Model Monitor – Fully Managed Automatic Monitoring For Your Machine Learning Models - Julien Simon | AWS Expert"/>
  <meta property="twitter:description" content="Expert analysis and technical deep-dive on amazon sagemaker model monitor – fully managed automatic monitoring for your machine learning models by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services."/>
  <meta property="twitter:image" content="https://julien.org/assets/julien-simon-aws-expert.jpg"/>
  <meta property="twitter:creator" content="@julsimon"/>
  
  <!-- Canonical URL -->
  <link rel="canonical" href="https://julien.org/blog/amazon-sagemaker-model-monitor-fully-managed-automatic-monitoring-for-your-machine-learning-models/"/>
  
  <!-- Author and Publisher -->
  <link rel="author" href="https://julien.org/"/>
  <link rel="publisher" href="https://julien.org/"/>
  
  <!-- Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "Amazon SageMaker Model Monitor – Fully Managed Automatic Monitoring For Your Machine Learning Models",
    "description": "Expert analysis and technical deep-dive on amazon sagemaker model monitor – fully managed automatic monitoring for your machine learning models by Julien Simon, leading AWS expert and former Global Technical Evangelist for AI & ML at Amazon Web Services.",
    "image": "https://julien.org/assets/julien-simon-aws-expert.jpg",
    "author": {
      "@type": "Person",
      "name": "Julien Simon",
      "url": "https://julien.org/",
      "jobTitle": "AWS Expert & Former Global Technical Evangelist",
      "worksFor": {
        "@type": "Organization",
        "name": "Amazon Web Services"
      },
      "sameAs": [
        "https://twitter.com/julsimon",
        "https://linkedin.com/in/juliensimon",
        "https://github.com/juliensimon"
      ]
    },
    "publisher": {
      "@type": "Organization",
      "name": "Julien Simon",
      "url": "https://julien.org/",
      "logo": {
        "@type": "ImageObject",
        "url": "https://julien.org/assets/julien-simon-logo.jpg"
      }
    },
    "datePublished": "2019-12-03T00:00:00Z",
    "dateModified": "2019-12-03T00:00:00Z",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://julien.org/blog/amazon-sagemaker-model-monitor-fully-managed-automatic-monitoring-for-your-machine-learning-models/"
    },
    "url": "https://julien.org/blog/amazon-sagemaker-model-monitor-fully-managed-automatic-monitoring-for-your-machine-learning-models/",
    "keywords": "AWS, Amazon Web Services, ['Amazon', 'SageMaker', 'Model'], machine learning, AI, cloud computing, Julien Simon, AWS expert",
    "articleSection": "AWS",
    "inLanguage": "en-US",
    "isPartOf": {
      "@type": "Blog",
      "name": "Julien Simon - AWS Expert Blog",
      "url": "https://julien.org/blog/"
    }
  }
  </script>
  
  <!-- Additional SEO Meta Tags -->
  <meta name="twitter:site" content="@julsimon"/>
  <meta name="twitter:creator" content="@julsimon"/>
  <meta name="theme-color" content="#FF9900"/>
  <meta name="msapplication-TileColor" content="#FF9900"/>
  <meta name="apple-mobile-web-app-capable" content="yes"/>
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>
  
  <!-- Preconnect to external domains -->
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="https://julien.org/favicon.ico"/>
  <link rel="apple-touch-icon" href="https://julien.org/apple-touch-icon.png"/>
  
  <style>
   body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        h1, h2, h3, h4, h5, h6 {
            color: #2c3e50;
            margin-top: 2em;
            margin-bottom: 0.5em;
        }
        h1 { font-size: 2.5em; }
        h2 { font-size: 2em; }
        h3 { font-size: 1.5em; }
        img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin: 1em 0;
        }
        /* Image alignment classes for text wraparound */
        img.alignleft {
            float: left;
            margin: 0.5em 1.5em 1em 0;
        }
        img.alignright {
            float: right;
            margin: 0.5em 0 1em 1.5em;
        }
        img.aligncenter {
            display: block;
            margin: 1em auto;
            float: none;
        }
        img.alignnone {
            float: none;
            margin: 1em 0;
        }
        /* Clear floats after images */
        .wp-block-image::after,
        p:has(img.alignleft)::after,
        p:has(img.alignright)::after {
            content: "";
            display: table;
            clear: both;
        }
        pre {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 1em;
            overflow-x: auto;
        }
        code {
            background: #f8f9fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: 'Monaco', 'Consolas', monospace;
        }
        blockquote {
            border-left: 4px solid #3498db;
            margin: 1em 0;
            padding-left: 1em;
            font-style: italic;
            color: #7f8c8d;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        p {
            margin-bottom: 1em;
        }
        .author-bio {
            background: #f8f9fa;
            border-left: 4px solid #FF9900;
            padding: 1em;
            margin: 2em 0;
            border-radius: 4px;
        }
        .author-bio h3 {
            margin-top: 0;
            color: #FF9900;
        }
        
  </style>
 </head>
 <body>
  <div style="margin-bottom: 1em;">
  <a href="../../../aws-blog-posts.html" style="color: #FF9900; text-decoration: none; font-size: 0.9em;">← Back to AWS Blog Posts</a>
</div>
  
  <h1>Amazon SageMaker Model Monitor – Fully Managed Automatic Monitoring For Your Machine Learning Models</h1>
  
    <div class="author-bio">
   <h3>About the Author</h3>
   <p><strong>Julien Simon</strong> is an expert in Practical AI, currently serving as Chief Evangelist at Arcee AI. Named <strong>#1 AI Evangelist globally by AI Magazine in 2021</strong>, he champions cost-effective, privacy-first AI solutions through Small Language Models, challenging the industry trend toward expensive, large-scale alternatives.</p>
   <p>With over 30 years of technology leadership—including executive roles at AWS, Hugging Face, Criteo, and other major companies—Julien has delivered 650+ speaking engagements across 90+ cities in 38 countries. His practical approach empowers enterprises to achieve superior AI outcomes while maintaining cost efficiency and operational simplicity.</p>
   <p>Follow Julien on <a href="https://twitter.com/julsimon" target="_blank">Twitter</a> and <a href="https://linkedin.com/in/juliensimon" target="_blank">LinkedIn</a> for the latest insights on Practical AI, Small Language Models, and enterprise AI solutions.</p>
  </div>
  
  <p style="color: #666; font-style: italic; margin-bottom: 1em;">
   Published: 2019-12-03 | Originally published at <a href="https://aws.amazon.com/blogs/aws/amazon-sagemaker-model-monitor-fully-managed-automatic-monitoring-for-your-machine-learning-models/" target="_blank" rel="noopener noreferrer">AWS Blog</a>
  </p>
 <body>
  <p>
   Today, we’re extremely happy to announce Amazon SageMaker Model Monitor, a new capability of
   <a href="https://aws.amazon.com/sagemaker/">
    Amazon SageMaker
   </a>
   that automatically monitors machine learning (ML) models in production, and alerts you when data quality issues appear.
  </p>
  <p>
   The first thing I learned when I started working with data is that there is no such thing as paying too much attention to data quality. Raise your hand if you’ve spent hours hunting down problems caused by unexpected NULL values or by exotic character encodings that somehow ended up in one of your databases.
  </p>
  <p>
   As models are literally built from large amounts of data, it’s easy to see why ML practitioners spend so much time caring for their data sets. In particular, they make sure that data samples in the training set (used to train the model) and in the validation set (used to measure its accuracy) have the same statistical properties.
  </p>
  <p>
   There be monsters! Although you have full control over your experimental data sets, the same can’t be said for real-life data that your models will receive. Of course, that data will be unclean, but a more worrisome problem is “data drift”, i.e. a gradual shift in the very statistical nature of the data you receive. Minimum and maximum values, mean, average, variance, and more: all these are key attributes that shape assumptions and decisions made during the training of a model. Intuitively, you can surely feel that any significant change in these values would impact the accuracy of predictions: imagine a loan application predicting higher amounts because input features are drifting or even missing!
  </p>
  <p>
   Detecting these conditions is pretty difficult: you would need to capture data received by your models, run all kinds of statistical analysis to compare that data to the training set, define rules to detect drift, send alerts if it happens… and do it all over again each time you update your models. Expert ML practitioners certainly know how to build these complex tools, but at the great expense of time and resources. Undifferentiated heavy lifting strikes again…
  </p>
  <p>
   To help all customers focus on creating value instead, we built
   <a href="https://aws.amazon.com/sagemaker/model-monitor">
    Amazon SageMaker Model Monitor
   </a>
   . Let me tell you more.
  </p>
  <p>
   <strong>
    <span style="text-decoration: underline;">
     Introducing Amazon SageMaker Model Monitor
     <br/>
    </span>
   </strong>
   A typical monitoring session goes like this. You first start from a
   <span title="Amazon SageMaker">
    SageMaker
   </span>
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html">
    endpoint
   </a>
   to monitor, either an existing one, or a new one created specifically for monitoring purposes. You can use SageMaker Model Monitor on any endpoint, whether the model was trained with a
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html">
    built-in algorithm
   </a>
   , a
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/frameworks.html">
    built-in framework
   </a>
   , or
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">
    your own container
   </a>
   .
  </p>
  <p>
   Using the SageMaker
   <a href="https://sagemaker.readthedocs.io/en/stable/">
    SDK
   </a>
   , you can capture a configurable fraction of the data sent to the endpoint (you can also capture predictions if you’d like), and store it in one of your
   <a href="https://aws.amazon.com/s3/">
    Amazon Simple Storage Service (Amazon S3)
   </a>
   buckets. Captured data is enriched with metadata (content type, timestamp, etc.), and you can secure and access it just like any S3 object.
  </p>
  <p>
   Then, you create a baseline from the data set that was used to train the model deployed on the endpoint (of course, you can reuse an existing baseline, too). This will fire up a
   <a href="https://aws.amazon.com/sagemaker/">
    Amazon SageMaker Processing
   </a>
   job where SageMaker Model Monitor will:
  </p>
  <ul>
   <li>
    Infer a schema for the input data, i.e. type and completeness information for each feature. You should review it, and update it if needed.
   </li>
   <li>
    For pre-built containers only, compute feature statistics using
    <a href="https://github.com/awslabs/deequ">
     Deequ
    </a>
    , an open source tool based on
    <a href="https://spark.apache.org">
     Apache Spark
    </a>
    that is
    <a href="https://aws.amazon.com/blogs/big-data/test-data-quality-at-scale-with-deequ/">
     developed and used
    </a>
    at Amazon (
    <a href="https://aws.amazon.com/blogs/big-data/test-data-quality-at-scale-with-deequ/">
     blog post
    </a>
    and
    <a href="http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf" rel="noopener noreferrer" target="_blank">
     research paper
    </a>
    ). These statistics include
    <a href="https://arxiv.org/abs/1603.05346">
     KLL sketches
    </a>
    , an advanced technique to compute accurate quantiles on streams of data, that we recently
    <a href="https://github.com/awslabs/deequ/pull/157">
     contributed
    </a>
    to Deequ.
   </li>
  </ul>
  <p>
   Using these artifacts, the next step is to launch a monitoring schedule, to let SageMaker Model Monitor inspect collected data and prediction quality. Whether you’re using a built-in or custom container, a number of built-in rules are applied, and reports are periodically pushed to S3. The reports contain statistics and schema information on the data received during the latest time frame, as well as any violation that was detected.
  </p>
  <p>
   Last but not least, SageMaker Model Monitor emits per-feature metrics to
   <a href="https://aws.amazon.com/cloudwatch/">
    Amazon CloudWatch
   </a>
   , which you can use to set up dashboards and alerts. The summary metrics from
   <span title="Amazon CloudWatch">
    CloudWatch
   </span>
   are also visible in
   <a href="https://aws.amazon.com/sagemaker/studio">
    Amazon SageMaker Studio
   </a>
   , and of course all statistics, monitoring results and data collected can be viewed and further analyzed in a notebook.
  </p>
  <p>
   For more information and an example on how to use SageMaker Model Monitor using
   <a href="https://aws.amazon.com/cloudformation/">
    AWS CloudFormation
   </a>
   , refer to the
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html">
    developer guide
   </a>
   .
  </p>
  <p>
   Now, let’s do a demo, using a
   <a href="https://github.com/awslabs/amazon-sagemaker-examples/tree/master/introduction_to_applying_machine_learning/xgboost_customer_churn">
    churn prediction
   </a>
   model trained with the built-in
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html">
    XGBoost
   </a>
   algorithm.
  </p>
  <p>
   <strong>
    <span style="text-decoration: underline;">
     Enabling Data Capture
     <br/>
    </span>
   </strong>
   The first step is to create an
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateEndpointConfig.html">
    endpoint configuration
   </a>
   to enable data capture. Here, I decide to capture 100% of incoming data, as well as model output (i.e. predictions). I’m also passing the content types for CSV and JSON data.
  </p>
  <pre><code class="lang-python">data_capture_configuration = {
    "EnableCapture": True,
    "InitialSamplingPercentage": 100,
    "DestinationS3Uri": s3_capture_upload_path,
    "CaptureOptions": [
        { "CaptureMode": "Output" },
        { "CaptureMode": "Input" }
    ],
    "CaptureContentTypeHeader": {
       "CsvContentTypes": ["text/csv"],
       "JsonContentTypes": ["application/json"]
}</code></pre>
  <p>
   Next, I create the endpoint using the usual
   <code>
    CreateEndpoint
   </code>
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateEndpoint.html">
    API
   </a>
   .
  </p>
  <pre><code class="lang-python">create_endpoint_config_response = sm_client.create_endpoint_config(
    EndpointConfigName = endpoint_config_name,
    ProductionVariants=[{
        'InstanceType':'ml.m5.xlarge',
        'InitialInstanceCount':1,
        'InitialVariantWeight':1,
        'ModelName':model_name,
        'VariantName':'AllTrafficVariant'
    }],
    DataCaptureConfig = data_capture_configuration)</code></pre>
  <p>
   On an existing endpoint, I would have used the
   <code>
    UpdateEndpoint
   </code>
   <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_UpdateEndpoint.html">
    API
   </a>
   to seamlessly update the endpoint configuration.
  </p>
  <p>
   After invoking the endpoint repeatedly, I can see some captured data in S3 (output was edited for clarity).
  </p>
  <pre><code class="lang-bash">$ aws s3 ls --recursive s3://sagemaker-us-west-2-123456789012/sagemaker/DEMO-ModelMonitor/datacapture/DEMO-xgb-churn-pred-model-monitor-2019-11-22-07-59-33/
</code><code class="lang-bash">AllTrafficVariant/2019/11/22/08/24-40-519-9a9273ca-09c2-45d3-96ab-fc7be2402d43.jsonl
AllTrafficVariant/2019/11/22/08/25-42-243-3e1c653b-8809-4a6b-9d51-69ada40bc809.jsonl</code></pre>
  <p>
   Here’s a line from one of these files.
  </p>
  <pre><code class="lang-json">    "endpointInput":{
        "observedContentType":"text/csv",
        "mode":"INPUT",
        "data":"132,25,113.2,96,269.9,107,229.1,87,7.1,7,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1",
        "encoding":"CSV"
     },
     "endpointOutput":{
        "observedContentType":"text/csv; charset=utf-8",
        "mode":"OUTPUT",
        "data":"0.01076381653547287",
        "encoding":"CSV"}
     },
    "eventMetadata":{
        "eventId":"6ece5c74-7497-43f1-a263-4833557ffd63",
        "inferenceTime":"2019-11-22T08:24:40Z"},
        "eventVersion":"0"}
</code></pre>
  <p>
   Pretty much what I expected. Now, let’s create a baseline for this model.
  </p>
  <p>
   <span style="text-decoration: underline;">
    <strong>
     Creating A Monitoring Baseline
     <br/>
    </strong>
   </span>
   This is a very simple step: pass the location of the baseline data set, and the location where results should be stored.
  </p>
  <pre><code class="lang-python">from processingjob_wrapper import ProcessingJob

processing_job = ProcessingJob(sm_client, role).
   create(job_name, baseline_data_uri, baseline_results_uri)
</code></pre>
  <p>
   Once that job is complete, I can see two new objects in S3: one for statistics, and one for constraints.
  </p>
  <pre><code class="lang-bash">aws s3 ls s3://sagemaker-us-west-2-123456789012/sagemaker/DEMO-ModelMonitor/baselining/results/
constraints.json
statistics.json</code></pre>
  <p>
   The
   <code>
    constraints.json
   </code>
   file tells me about the inferred schema for the training data set (don’t forget to check it’s accurate). Each feature is typed, and I also get information on whether a feature is always present or not (1.0 means 100% here). Here are the first few lines.
  </p>
  <pre><code class="lang-json">{
  "version" : 0.0,
  "features" : [ {
    "name" : "Churn",
    "inferred_type" : "Integral",
    "completeness" : 1.0
  }, {
    "name" : "Account Length",
    "inferred_type" : "Integral",
    "completeness" : 1.0
  }, {
    "name" : "VMail Message",
    "inferred_type" : "Integral",
    "completeness" : 1.0
  }, {
    "name" : "Day Mins",
    "inferred_type" : "Fractional",
    "completeness" : 1.0
  }, {
    "name" : "Day Calls",
    "inferred_type" : "Integral",
    "completeness" : 1.0</code></pre>
  <p>
   At the end of that file, I can see configuration information for
   <span title="Amazon CloudWatch">
    CloudWatch
   </span>
   monitoring: turn it on or off, set the drift threshold, etc.
  </p>
  <pre><code class="lang-python">"monitoring_config" : {
    "evaluate_constraints" : "Enabled",
    "emit_metrics" : "Enabled",
    "distribution_constraints" : {
      "enable_comparisons" : true,
      "min_domain_mass" : 1.0,
      "comparison_threshold" : 1.0
    }
  }</code></pre>
  <p>
   The
   <code>
    statistics.json
   </code>
   file shows different statistics for each feature (mean, average, quantiles, etc.), as well as unique values received by the endpoint. Here’s an example.
  </p>
  <pre><code class="lang-json">"name" : "Day Mins",
    "inferred_type" : "Fractional",
    "numerical_statistics" : {
      "common" : {
        "num_present" : 2333,
        "num_missing" : 0
      },
      "mean" : 180.22648949849963,
      "sum" : 420468.3999999996,
      "std_dev" : 53.987178959901556,
      "min" : 0.0,
      "max" : 350.8,
      "distribution" : {
        "kll" : {
          "buckets" : [ {
            "lower_bound" : 0.0,
            "upper_bound" : 35.08,
            "count" : 14.0
          }, {
            "lower_bound" : 35.08,
            "upper_bound" : 70.16,
            "count" : 48.0
          }, {
            "lower_bound" : 70.16,
            "upper_bound" : 105.24000000000001,
            "count" : 130.0
          }, {
            "lower_bound" : 105.24000000000001,
            "upper_bound" : 140.32,
            "count" : 318.0
          }, {
            "lower_bound" : 140.32,
            "upper_bound" : 175.4,
            "count" : 565.0
          }, {
            "lower_bound" : 175.4,
            "upper_bound" : 210.48000000000002,
            "count" : 587.0
          }, {
            "lower_bound" : 210.48000000000002,
            "upper_bound" : 245.56,
            "count" : 423.0
          }, {
            "lower_bound" : 245.56,
            "upper_bound" : 280.64,
            "count" : 180.0
          }, {
            "lower_bound" : 280.64,
            "upper_bound" : 315.72,
            "count" : 58.0
          }, {
            "lower_bound" : 315.72,
            "upper_bound" : 350.8,
            "count" : 10.0
          } ],
          "sketch" : {
            "parameters" : {
              "c" : 0.64,
              "k" : 2048.0
            },
            "data" : [ [ 178.1, 160.3, 197.1, 105.2, 283.1, 113.6, 232.1, 212.7, 73.3, 176.9, 161.9, 128.6, 190.5, 223.2, 157.9, 173.1, 273.5, 275.8, 119.2, 174.6, 133.3, 145.0, 150.6, 220.2, 109.7, 155.4, 172.0, 235.6, 218.5, 92.7, 90.7, 162.3, 146.5, 210.1, 214.4, 194.4, 237.3, 255.9, 197.9, 200.2, 120, ...</code></pre>
  <p>
   Now, let’s start monitoring our endpoint.
  </p>
  <p>
   <strong>
    <span style="text-decoration: underline;">
     Monitoring An Endpoint
     <br/>
    </span>
   </strong>
   Again, one API call is all that it takes: I simply create a monitoring schedule for my endpoint, passing the constraints and statistics file for the baseline data set. Optionally, I could also pass preprocessing and postprocessing functions, should I want to tweak data and predictions.
  </p>
  <pre><code class="lang-python">ms = MonitoringSchedule(sm_client, role)
schedule = ms.create(
   mon_schedule_name, 
   endpoint_name, 
   s3_report_path, 
   # record_preprocessor_source_uri=s3_code_preprocessor_uri, 
   # post_analytics_source_uri=s3_code_postprocessor_uri,
   baseline_statistics_uri=baseline_results_uri + '/statistics.json',
   baseline_constraints_uri=baseline_results_uri+ '/constraints.json'
)</code></pre>
  <p>
   Then, I start sending bogus data to the endpoint, i.e. samples constructed from random values, and I wait for SageMaker Model Monitor to start generating reports. The suspense is killing me!
  </p>
  <p>
   <strong>
    <span style="text-decoration: underline;">
     Inspecting Reports
    </span>
   </strong>
   <br/>
   Quickly, I see that reports are available in S3.
  </p>
  <pre><code class="lang-python">mon_executions = sm_client.list_monitoring_executions(MonitoringScheduleName=mon_schedule_name, MaxResults=3)
for execution_summary in mon_executions['MonitoringExecutionSummaries']:
    print("ProcessingJob: {}".format(execution_summary['ProcessingJobArn'].split('/')[1]))
    print('MonitoringExecutionStatus: {} \n'.format(execution_summary['MonitoringExecutionStatus']))

ProcessingJob: model-monitoring-201911221050-df2c7fc4
MonitoringExecutionStatus: Completed 

ProcessingJob: model-monitoring-201911221040-3a738dd7
MonitoringExecutionStatus: Completed 

ProcessingJob: model-monitoring-201911221030-83f15fb9
MonitoringExecutionStatus: Completed </code></pre>
  <p>
   Let’s find the reports for one of these monitoring jobs.
  </p>
  <pre><code class="lang-python">desc_analytics_job_result=sm_client.describe_processing_job(ProcessingJobName=job_name)
report_uri=desc_analytics_job_result['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']
print('Report Uri: {}'.format(report_uri))

Report Uri: s3://sagemaker-us-west-2-123456789012/sagemaker/DEMO-ModelMonitor/reports/2019112208-2019112209</code></pre>
  <p>
   Ok, so what do we have here?
  </p>
  <pre><code class="lang-bash">aws s3 ls s3://sagemaker-us-west-2-123456789012/sagemaker/DEMO-ModelMonitor/reports/2019112208-2019112209/

constraint_violations.json
constraints.json
statistics.json</code></pre>
  <p>
   As you would expect, the
   <code>
    constraints.json
   </code>
   and
   <code>
    statistics.json
   </code>
   contain schema and statistics information on the data samples processed by the monitoring job. Let’s open directly the third one,
   <code>
    constraints_violations.json
   </code>
   !
  </p>
  <pre><code class="lang-json">violations" : [ {
    "feature_name" : "State_AL",
    "constraint_check_type" : "data_type_check",
    "description" : "Value: 0.8 does not meet the constraint requirement! "
  }, {
    "feature_name" : "Eve Mins",
    "constraint_check_type" : "baseline_drift_check",
    "description" : "Numerical distance: 0.2711598746081505 exceeds numerical threshold: 0"
  }, {
    "feature_name" : "CustServ Calls",
    "constraint_check_type" : "baseline_drift_check",
    "description" : "Numerical distance: 0.6470588235294117 exceeds numerical threshold: 0"
  }</code></pre>
  <p>
   Oops! It looks like I’ve been assigning floating point values to integer features: surely that’s not going to work too well!
  </p>
  <p>
   Some features are also exhibiting drift, that’s not good either. Maybe something is wrong with my data ingestion process, or maybe the distribution of data has actually changed, and I need to retrain the model. As all this information is available as
   <span title="Amazon CloudWatch">
    CloudWatch
   </span>
   metrics, I could define thresholds, set alarms and even trigger new training jobs automatically.
  </p>
  <p>
   <span style="text-decoration: underline;">
    <strong>
     Now Available!
    </strong>
   </span>
   <br/>
   As you can see,
   <a href="https://aws.amazon.com/sagemaker/model-monitor">
    Amazon SageMaker Model Monitor
   </a>
   is easy to set up, and helps you quickly know about quality issues in your ML models.
  </p>
  <p>
   Now it’s your turn: you can start using
   <a href="https://aws.amazon.com/sagemaker/model-monitor">
    Amazon SageMaker Model Monitor
   </a>
   today in all commercial regions where
   <a href="https://aws.amazon.com/sagemaker/">
    Amazon SageMaker
   </a>
   is available. This capability is also integrated in
   <a href="https://aws.amazon.com/sagemaker/studio">
    Amazon SageMaker Studio
   </a>
   , our workbench for ML projects.
  </p>
  <p>
   Give it a try and please send us feedback, either on the
   <a href="https://forums.aws.amazon.com/forum.jspa?forumID=285">
    AWS forum for Amazon SageMaker
   </a>
   , or through your usual AWS support contacts.
  </p>
  <a href="https://aws.amazon.com/developer/community/evangelists/julien-simon/">
   - Julien
  </a>
  <!-- '"` -->
 
  
  </body>
 </html>

<!DOCTYPE html>
<html>
 <head>
    <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  
  <!-- Primary Meta Tags -->
  <title>How Hugging Face Accelerated Development Of Witty Works Writing Assistant - Julien Simon | Open Source AI Expert</title>
  <meta name="title" content="How Hugging Face Accelerated Development Of Witty Works Writing Assistant - Julien Simon | Open Source AI Expert"/>
  <meta name="description" content="Expert analysis and technical deep-dive on how hugging face accelerated development of witty works writing assistant by Julien Simon, leading voice in open-source AI and former Chief Evangelist at Hugging Face. Comprehensive insights on transformers, small language models, and AI accessibility."/>
  <meta name="keywords" content="Hugging Face, Transformers, Open Source AI, Small Language Models, Machine Learning, AI, Natural Language Processing, NLP, Julien Simon, AI Expert, Open Source Expert, Hugging Face ExpertHugging-Face-Accelerated-Development-Of-Witty-Works-Writing-Assistant, How Hugging Face Accelerated Development Of Witty Works Writing Assistant"/>
  <meta name="author" content="Julien Simon"/>
  <meta name="robots" content="index, follow"/>
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article"/>
  <meta property="og:url" content="https://julien.org/blog/2023-03-01-how-hugging-face-accelerated-development-of-witty-works-writing-assistant/"/>
  <meta property="og:title" content="How Hugging Face Accelerated Development Of Witty Works Writing Assistant - Julien Simon | Open Source AI Expert"/>
  <meta property="og:description" content="Expert analysis and technical deep-dive on how hugging face accelerated development of witty works writing assistant by Julien Simon, leading voice in open-source AI and former Chief Evangelist at Hugging Face. Comprehensive insights on transformers, small language models, and AI accessibility."/>
  <meta property="og:image" content="https://julien.org/assets/julien-simon-huggingface-expert.jpg"/>
  <meta property="og:site_name" content="Julien Simon - Open Source AI Expert"/>
  <meta property="article:author" content="Julien Simon"/>
  <meta property="article:published_time" content="2023-03-01T00:00:00Z"/>
  <meta property="article:section" content="Hugging Face"/>
  <meta property="article:tag" content="Hugging Face, Open Source AI, Transformers, Small Language Models"/>
  
  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image"/>
  <meta property="twitter:url" content="https://julien.org/blog/2023-03-01-how-hugging-face-accelerated-development-of-witty-works-writing-assistant/"/>
  <meta property="twitter:title" content="How Hugging Face Accelerated Development Of Witty Works Writing Assistant - Julien Simon | Open Source AI Expert"/>
  <meta property="twitter:description" content="Expert analysis and technical deep-dive on how hugging face accelerated development of witty works writing assistant by Julien Simon, leading voice in open-source AI and former Chief Evangelist at Hugging Face. Comprehensive insights on transformers, small language models, and AI accessibility."/>
  <meta property="twitter:image" content="https://julien.org/assets/julien-simon-huggingface-expert.jpg"/>
  <meta property="twitter:creator" content="@julsimon"/>
  
  <!-- Canonical URL -->
  <link rel="canonical" href="https://julien.org/blog/2023-03-01-how-hugging-face-accelerated-development-of-witty-works-writing-assistant/"/>
  
  <!-- Author and Publisher -->
  <link rel="author" href="https://julien.org/"/>
  <link rel="publisher" href="https://julien.org/"/>
  
  <!-- Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "How Hugging Face Accelerated Development Of Witty Works Writing Assistant",
    "description": "Expert analysis and technical deep-dive on how hugging face accelerated development of witty works writing assistant by Julien Simon, leading voice in open-source AI and former Chief Evangelist at Hugging Face. Comprehensive insights on transformers, small language models, and AI accessibility.",
    "image": "https://julien.org/assets/julien-simon-huggingface-expert.jpg",
    "author": {
      "@type": "Person",
      "name": "Julien Simon",
      "url": "https://julien.org/",
      "jobTitle": "Open Source AI Expert & Former Chief Evangelist",
      "worksFor": {
        "@type": "Organization",
        "name": "Hugging Face"
      },
      "sameAs": [
        "https://twitter.com/julsimon",
        "https://linkedin.com/in/juliensimon",
        "https://github.com/juliensimon"
      ]
    },
    "publisher": {
      "@type": "Organization",
      "name": "Julien Simon",
      "url": "https://julien.org/",
      "logo": {
        "@type": "ImageObject",
        "url": "https://julien.org/assets/julien-simon-logo.jpg"
      }
    },
    "datePublished": "2023-03-01T00:00:00Z",
    "dateModified": "2023-03-01T00:00:00Z",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://julien.org/blog/2023-03-01-how-hugging-face-accelerated-development-of-witty-works-writing-assistant/"
    },
    "url": "https://julien.org/blog/2023-03-01-how-hugging-face-accelerated-development-of-witty-works-writing-assistant/",
    "keywords": "Hugging Face, Transformers, Open Source AI, Small Language Models, Machine Learning, AI, Natural Language Processing, NLP, Julien Simon, AI Expert, Open Source Expert, Hugging Face Expert, How-Hugging-Face-Accelerated-Development-Of-Witty-Works-Writing-Assistant",
    "articleSection": "Hugging Face",
    "inLanguage": "en-US",
    "isPartOf": {
      "@type": "Blog",
      "name": "Julien Simon - Open Source AI Expert Blog",
      "url": "https://julien.org/blog/"
    }
  }
  </script>
  
  <!-- Additional SEO Meta Tags -->
  <meta name="twitter:site" content="@julsimon"/>
  <meta name="twitter:creator" content="@julsimon"/>
  <meta name="theme-color" content="#FF6B35"/>
  <meta name="msapplication-TileColor" content="#FF6B35"/>
  <meta name="apple-mobile-web-app-capable" content="yes"/>
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>
  
  <!-- Preconnect to external domains -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="https://julien.org/assets/favicon.ico">
  
  <!-- Security Headers -->
  <meta http-equiv="X-Content-Type-Options" content="nosniff">
  <meta http-equiv="X-Frame-Options" content="DENY">
  <meta http-equiv="Referrer-Policy" content="strict-origin-when-cross-origin">
  <meta http-equiv="X-XSS-Protection" content="1; mode=block">
  <meta http-equiv="Permissions-Policy" content="camera=(), microphone=(), geolocation=(), interest-cohort=()">
  <meta http-equiv="Cross-Origin-Opener-Policy" content="same-origin">
  <meta http-equiv="Cross-Origin-Embedder-Policy" content="require-corp">

  
  <style>
   body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        h1, h2, h3, h4, h5, h6 {
            color: #2c3e50;
            margin-top: 2em;
            margin-bottom: 0.5em;
        }
        h1 { font-size: 2.5em; }
        h2 { font-size: 2em; }
        h3 { font-size: 1.5em; }
        img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin: 1em 0;
        }
        /* Image alignment classes for text wraparound */
        img.alignleft {
            float: left;
            margin: 0.5em 1.5em 1em 0;
        }
        img.alignright {
            float: right;
            margin: 0.5em 0 1em 1.5em;
        }
        img.aligncenter {
            display: block;
            margin: 1em auto;
            float: none;
        }
        img.alignnone {
            float: none;
            margin: 1em 0;
        }
        /* Clear floats after images */
        .wp-block-image::after,
        p:has(img.alignleft)::after,
        p:has(img.alignright)::after {
            content: "";
            display: table;
            clear: both;
        }
        pre {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 1em;
            overflow-x: auto;
        }
        code {
            background: #f8f9fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: 'Monaco', 'Consolas', monospace;
        }
        blockquote {
            border-left: 4px solid #3498db;
            margin: 1em 0;
            padding-left: 1em;
            font-style: italic;
            color: #7f8c8d;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        p {
            margin-bottom: 1em;
        }
        /* Hugging Face specific styling */
        .prose {
            max-width: none;
        }
        .prose pre {
            background: #1e293b;
            color: #e2e8f0;
        }
        .prose code {
            background: #f1f5f9;
            color: #dc2626;
        }
  </style>
 </head>
 <body>

  <div style="margin-bottom: 2em;">
   <a href="../../../../huggingface-blog-posts.html" style="color: #3498db; text-decoration: none; font-weight: 500;">‚Üê Back to Hugging Face Blog Posts</a>
  </div>
  <h1>
   How Hugging Face Accelerated Development of Witty Works Writing Assistant
  </h1>
  <p style="color: #666; font-style: italic; margin-bottom: 1em;">
   Published: 2023-03-01
  </p>
  
  <p style="color: #666; font-style: italic; margin-bottom: 2em;">
   Originally published at
   <a href="https://huggingface.co/blog/classification-use-cases">
    https://huggingface.co/blog/classification-use-cases
   </a>
  </p>
  <!-- HTML_TAG_START -->
  <h2 class="relative group flex items-center">
   <span>
    The Success Story of Witty Works with the Hugging Face Expert Acceleration Program.
   </span>
  </h2>
  <p>
   <em>
    If you're interested in building ML solutions faster, visit the
    <a href="https://huggingface.co/support?utm_source=blog-post&amp;utm_medium=blog-post&amp;utm_campaign=blog-post-classification-use-case">
     Expert Acceleration Program
    </a>
    landing page and contact us
    <a href="https://huggingface.co/support?utm_source=blog-post&amp;utm_medium=blog-post&amp;utm_campaign=blog-post-classification-use-case#form">
     here
    </a>
    !
   </em>
  </p>
  <h3 class="relative group flex items-center">
   <span>
    Business Context
   </span>
  </h3>
  <p>
   As IT continues to evolve and reshape our world, creating a more diverse and inclusive environment within the industry is imperative.
   <a href="https://www.witty.works/">
    Witty Works
   </a>
   was built in 2018 to address this challenge. Starting as a consulting company advising organizations on becoming more diverse, Witty Works first helped them write job ads using inclusive language. To scale this effort, in 2019, they built a web app to assist users in writing inclusive job ads in English, French and German. They enlarged the scope rapidly with a writing assistant working as a browser extension that automatically fixes and explains potential bias in emails, Linkedin posts, job ads, etc. The aim was to offer a solution for internal and external communication that fosters a cultural change by providing micro-learning bites that explain the underlying bias of highlighted words and phrases.
  </p>
  <p align="center">
   <img src="image01.webp"/>
   <br/>
   <em>
    Example of suggestions by the writing assistant
   </em>
  </p>
  <h3 class="relative group flex items-center">
   <span>
    First experiments
   </span>
  </h3>
  <p>
   Witty Works first chose a basic machine learning approach to build their assistant from scratch. Using transfer learning with pre-trained spaCy models, the assistant was able to:
  </p>
  <ul>
   <li>
    Analyze text and transform words into lemmas,
   </li>
   <li>
    Perform a linguistic analysis,
   </li>
   <li>
    Extract the linguistic features from the text (plural and singular forms, gender), part-of-speech tags (pronouns, verbs, nouns, adjectives, etc.), word dependencies labels, named entity recognition, etc.
   </li>
  </ul>
  <p>
   By detecting and filtering words according to a specific knowledge base using linguistic features, the assistant could highlight non-inclusive words and suggest alternatives in real-time.
  </p>
  <h3 class="relative group flex items-center">
   <span>
    Challenge
   </span>
  </h3>
  <p>
   The vocabulary had around 2300 non-inclusive words and idioms in German and English correspondingly. And the above described basic approach worked well for 85% of the vocabulary but failed for context-dependent words. Therefore the task was to build a context-dependent classifier of non-inclusive words. Such a challenge (understanding the context rather than recognizing linguistic features) led to using Hugging Face transformers.
  </p>
  <pre><code class="language-diff">Example of context dependent non-inclusive words: 
Fossil fuels are not renewable resources. Vs He is an old fossil
You will have a flexible schedule. Vs You should keep your schedule flexible.
</code></pre>
  <h3 class="relative group flex items-center">
   <span>
    Solutions provided by the
    <a href="https://huggingface.co/support?utm_source=blog-post&amp;utm_medium=blog-post&amp;utm_campaign=blog-post-classification-use-case">
     Hugging Face Experts
    </a>
   </span>
  </h3>
  <ul>
   <li>
    <h4 class="relative group flex items-center">
     <span>
      <strong>
       Get guidance for deciding on the right ML approach.
      </strong>
     </span>
    </h4>
   </li>
  </ul>
  <p>
   The initial chosen approach was vanilla transformers (used to extract token embeddings of specific non-inclusive words). The Hugging Face Expert recommended switching from contextualized word embeddings to contextualized sentence embeddings. In this approach, the representation of each word in a sentence depends on its surrounding context.
  </p>
  <p>
   Hugging Face Experts suggested the use of a
   <a href="https://www.sbert.net/">
    Sentence Transformers
   </a>
   architecture. This architecture generates embeddings for sentences as a whole. The distance between semantically similar sentences is minimized and maximized for distant sentences.
  </p>
  <p>
   In this approach, Sentence Transformers use Siamese networks and triplet network structures to modify the pre-trained transformer models to generate ‚Äúsemantically meaningful‚Äù sentence embeddings.
  </p>
  <p>
   The resulting sentence embedding serves as input for a classical classifier based on KNN or logistic regression to build a context-dependent classifier of non-inclusive words.
  </p>
  <pre><code class="language-diff">Elena Nazarenko, Lead Data Scientist at Witty Works: 
‚ÄúWe generate contextualized embedding vectors for every word depending on its 
sentence (BERT embedding). Then, we keep only the embedding for the ‚Äúproblem‚Äù 
word‚Äôs token, and calculate the smallest angle (cosine similarity)‚Äù  
</code></pre>
  <p>
   To fine-tune a vanilla transformers-based classifier, such as a simple BERT model, Witty Works would have needed a substantial amount of annotated data. Hundreds of samples for each category of flagged words would have been necessary. However, such an annotation process would have been costly and time-consuming, which Witty Works couldn‚Äôt afford.
  </p>
  <ul>
   <li>
    <h4 class="relative group flex items-center">
     <span>
      <strong>
       Get guidance on selecting the right ML library.
      </strong>
     </span>
    </h4>
   </li>
  </ul>
  <p>
   The Hugging Face Expert suggested using the Sentence Transformers Fine-tuning library (aka
   <a href="https://github.com/huggingface/setfit">
    SetFit
   </a>
   ), an efficient framework for few-shot fine-tuning of Sentence Transformers models. Combining contrastive learning and semantic sentence similarity, SetFit achieves high accuracy on text classification tasks with very little labeled data.
  </p>
  <pre><code class="language-diff">Julien Simon, Chief Evangelist at Hugging Face: 
‚ÄúSetFit for text classification tasks is a great tool to add to the ML toolbox‚Äù 
</code></pre>
  <p>
   The Witty Works team found the performance was adequate with as little as 15-20  labeled sentences per specific word.
  </p>
  <pre><code class="language-diff">Elena Nazarenko, Lead Data Scientist at Witty Works: 
‚ÄúAt the end of the day, we saved time and money by not creating this large data set‚Äù
</code></pre>
  <p>
   Reducing the number of sentences was essential to ensure that model training remained fast and that running the model was efficient. However, it was also necessary for another reason: Witty explicitly takes a highly supervised/rule-based approach to
   <a href="https://www.witty.works/en/blog/is-chatgpt-able-to-generate-inclusive-language">
    actively manage bias
   </a>
   . Reducing the number of sentences is very important to reduce the effort in manually reviewing the training sentences.
  </p>
  <ul>
   <li>
    <h4 class="relative group flex items-center">
     <span>
      <strong>
       Get guidance on selecting the right ML models.
      </strong>
     </span>
    </h4>
   </li>
  </ul>
  <p>
   One major challenge for Witty Works was deploying a model with low latency. No one expects to wait 3 minutes to get suggestions to improve one‚Äôs text! Both Hugging Face and Witty Works experimented with a few sentence transformers models and settled for
   <a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2">
    mpnet-base-v2
   </a>
   combined with logistic regression and KNN.
  </p>
  <p>
   After a first test on Google Colab, the Hugging Face experts guided Witty Works on deploying the model on Azure. No optimization was necessary as the model was fast enough.
  </p>
  <pre><code class="language-diff">Elena Nazarenko, Lead Data Scientist at Witty Works: 
‚ÄúWorking with Hugging Face saved us a lot of time and money. 
One can feel lost when implementing complex text classification use cases. 
As it is one of the most popular tasks, there are a lot of models on the Hub. 
The Hugging Face experts guided me through the massive amount of transformer-based 
models to choose the best possible approach. 
Plus, I felt very well supported during the model deployment‚Äù
</code></pre>
  <h3 class="relative group flex items-center">
   <span>
    <strong>
     Results and conclusion
    </strong>
   </span>
  </h3>
  <p>
   The number of training sentences dropped from 100-200 per word to 15-20 per word. Witty Works achieved an accuracy of 0.92 and successfully deployed a custom model on Azure with minimal DevOps effort!
  </p>
  <pre><code class="language-diff">Lukas Kahwe Smith CTO &amp; Co-founder of Witty Works: 
‚ÄúWorking on an IT project by oneself can be challenging and even if 
the EAP is a significant investment for a startup, it is the cheaper 
and most meaningful way to get a sparring partner‚Äú
</code></pre>
  <p>
   With the guidance of the Hugging Face experts, Witty Works saved time and money by implementing a new ML workflow in the Hugging Face way.
  </p>
  <pre><code class="language-diff">Julien Simon, Chief Evangelist at Hugging Face: 
‚ÄúThe Hugging way to build workflows: 
find open-source pre-trained models, 
evaluate them right away, 
see what works, see what does not. 
By iterating, you start learning  things immediately‚Äù 
</code></pre>
  <hr/>
  <p>
   ü§ó   If you or your team are interested in accelerating your ML roadmap with Hugging Face Experts, please visit
   <a href="https://huggingface.co/support?utm_source=blog-post&amp;utm_medium=blog-post&amp;utm_campaign=blog-post-classification-use-case">
    hf.co/support
   </a>
   to learn more.
  </p>
  <!-- HTML_TAG_END -->
  <hr/>
  <h3>
   About the Author
  </h3>
  <p>
   <strong>
    Julien Simon is the Chief Evangelist at Hugging Face
   </strong>
   , where he focuses on democratizing AI and making transformers accessible to everyone. A leading voice in open-source AI and small language models, he helps developers and enterprises bring their AI ideas to life. In his spare time, he reads the works of JRR Tolkien again and again.
  </p>
  <p>
  </p>
  <p>
  </p>
  <p>
  </p>
  <!-- '"` -->
 
  
  </body>
 </html>
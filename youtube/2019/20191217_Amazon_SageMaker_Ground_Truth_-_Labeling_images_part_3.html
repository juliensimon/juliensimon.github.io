<!DOCTYPE html>

<html lang="en">
<head>
<meta content="Amazon SageMaker Ground Truth   Labeling images part 3 - In this video, I show you how to label images, using the new automatic segmentation tool.

https://aws.amazon.com/sagemaker/groundtruth/
https://aws.amazon.com/..." name="description"/><meta content="Amazon SageMaker Ground Truth   Labeling images part 3 - Julien Simon" property="og:title"/><meta content="Amazon SageMaker Ground Truth   Labeling images part 3 - In this video, I show you how to label images, using the new automatic segmentation tool.

https://aws.amazon.com/sagemaker/groundtruth/
https://aws.amazon.com/..." property="og:description"/><meta content="https://www.julien.org/youtube/2019/20191217_Amazon_SageMaker_Ground_Truth_-_Labeling_images_part_3.html" property="og:url"/><meta content="video" property="og:type"/><meta content="summary_large_image" name="twitter:card"/><meta content="Amazon SageMaker Ground Truth   Labeling images part 3 - Julien Simon" name="twitter:title"/><meta content="Amazon SageMaker Ground Truth   Labeling images part 3 - In this video, I show you how to label images, using the new automatic segmentation tool.

https://aws.amazon.com/sagemaker/groundtruth/
https://aws.amazon.com/..." name="twitter:description"/><link href="https://www.julien.org/youtube/2019/20191217_Amazon_SageMaker_Ground_Truth_-_Labeling_images_part_3.html" rel="canonical"/><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Amazon SageMaker Ground Truth   Labeling images part 3 - Julien Simon</title>
<style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 2.2em;
        }
        .date {
            color: #7f8c8d;
            font-size: 1.1em;
            margin-bottom: 30px;
            font-weight: 500;
        }
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin-bottom: 30px;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
            border-radius: 8px;
        }
        .description {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .description a {
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }
        .description a:hover {
            color: #2980b9;
            text-decoration: underline;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .transcript h2 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tags {
            margin-bottom: 30px;
        }
        .tags h2 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tag {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 6px 12px;
            margin: 4px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }
        .links {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .link {
            display: inline-block;
            padding: 12px 24px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.3s;
        }
        .link:hover {
            background: #2980b9;
        }
        .link.youtube {
            background: #e74c3c;
        }
        .link.youtube:hover {
            background: #c0392b;
        }
        @media (max-width: 600px) {
            .container {
                padding: 20px;
                margin: 10px;
            }
            h1 {
                font-size: 1.8em;
            }
            .links {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
<div class="container">
<h1>Amazon SageMaker Ground Truth   Labeling images part 3</h1>
<div class="date">December 17, 2019</div>
<div class="video-container">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" src="https://www.youtube.com/embed/z1g6m3AqNYM">
</iframe>
</div>
<div class="description">In this video, I show you how to label images, using the new automatic segmentation tool.

<a href="https://aws.amazon.com/sagemaker/groundtruth/" rel="noopener noreferrer" target="_blank">https://aws.amazon.com/sagemaker/groundtruth/</a>
<a href="https://aws.amazon.com/blogs/machine-learning/auto-segmenting-objects-when-performing-semantic-segmentation-labeling-with-amazon-sagemaker-ground-truth/" rel="noopener noreferrer" target="_blank">https://aws.amazon.com/blogs/machine-learning/auto-segmenting-objects-when-performing-semantic-segmentation-labeling-with-amazon-sagemaker-ground-truth/</a>

Follow me on :
* Medium: <a href="https://medium.com/@julsimon" rel="noopener noreferrer" target="_blank">https://medium.com/@julsimon</a>
* Twitter: <a href="https://twitter.com/juliensimon" rel="noopener noreferrer" target="_blank">https://twitter.com/juliensimon</a></div>
<div class="transcript">
<h2>Transcript</h2>
            Alright, in the previous video, we created the labeling job and now we're ready to get to work. Let me switch to the worker console, the one I logged into previously using the account I created. Now I see this job that's ready for me to work on. So let's get to work.

Now we're going to be presented with the samples present in the dataset. On the left side, we see instructions. I stuck with generic instructions here. For real-life, production workloads, please make sure you pass meaningful, detailed instructions if you want your workers to do a good job. Now I see samples, and I see tools here to help me work. I also see the labels. Let's get to work.

This is the guitar player, and as it turns out, James is also the vocalist. That's an ambiguous sample here, but he's not actually singing; he's playing guitar. So let's treat him as a guitar player. We could gradually define the contour for this player using the polygon object. That's one way of doing it, and it does take a while. You need to be quite precise. You can zoom in and use these zoom tools. Here I'm going a little too fast, but okay. Hopefully, that's not too sloppy. Make sure you hit that last dot to complete the mask. Fine. We can zoom in or out and be extremely precise if we wanted to, but I guess for this one, that's all right. Let's submit this one and move on to the next. Oh, yeah, I need to validate the polygon and submit. Okay.

Here's another image to work on. We could try the polygon again or we could try this new feature that just came out last week, which lets you automatically segment. Let's select a guitarist again. Instead of drawing the polygon, we can try and define four points. It's not too bad. It's quicker than trying to build that polygon. Of course, we can use the eraser and refine the polygon. Refine our work. Okay, that's not too bad. Let's try that on the other guy. Oh, need to select the label first, of course. Alright, yeah. This one is not as good, but alright, we can take that. Just get a bigger brush. Even if it doesn't get it perfectly right, these are pretty difficult images because you have a very complex background and the lighting isn't easy to work with. Everything is kind of yellow. Anyway, you get the point. Let's try this one with auto-segmentation again. Oh, yeah, this one's pretty good. Nice. Maybe that guy too. All right. This is the best player again, sorry, best players. This one is the final one, so auto-segmentation again. Maybe here, yep. Okay, that's not too bad. This one here, okay, yeah, did better on that one with a little experience. You know where to put those dots in the optimal way. Right. Let's submit the image. I guess one more to go. Let's try to do those quick. Okay, not bad. Let's use the vocalist this time. Alright, pretty good. Submit. Alright, I'm done working, so I can log out. Now all those annotations are going to be saved. If I go back to my job here in a few minutes, I'm going to see annotated samples, and of course, I'm going to get the annotated manifest in S3. So let's wait for a few minutes, and then I'll show you the annotations and we'll quickly talk about how you use those to train models. ありがとうございました
        </div>
<div class="tags">
<h2>Tags</h2>
<span class="tag">Image Annotation</span><span class="tag">Polygon Tool</span><span class="tag">Auto-Segmentation</span><span class="tag">Worker Console</span><span class="tag">Labeling Job</span>
</div>
<div class="links"><a class="link" href="../../youtube.html">← Back to YouTube Overview</a></div>
</div>
</body>
</html>
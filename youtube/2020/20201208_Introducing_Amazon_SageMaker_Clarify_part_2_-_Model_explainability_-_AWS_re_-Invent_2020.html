<!DOCTYPE html>

<html lang="en">
<head>
<meta content="Introducing Amazon SageMaker Clarify part 2   Model explainability   AWS re  Invent 2020 - Following up on part 1 (https://youtu.be/jvcPZmnXaxo), I show how you to use the model explainability capability in Amazon SageMaker Clarify, using SHAP values ..." name="description"/><meta content="Introducing Amazon SageMaker Clarify part 2   Model explainability   AWS re  Invent 2020 - Julien Simon" property="og:title"/><meta content="Introducing Amazon SageMaker Clarify part 2   Model explainability   AWS re  Invent 2020 - Following up on part 1 (https://youtu.be/jvcPZmnXaxo), I show how you to use the model explainability capability in Amazon SageMaker Clarify, using SHAP values ..." property="og:description"/><meta content="https://www.julien.org/youtube/2020/20201208_Introducing_Amazon_SageMaker_Clarify_part_2_-_Model_explainability_-_AWS_re_-Invent_2020.html" property="og:url"/><meta content="video" property="og:type"/><meta content="summary_large_image" name="twitter:card"/><meta content="Introducing Amazon SageMaker Clarify part 2   Model explainability   AWS re  Invent 2020 - Julien Simon" name="twitter:title"/><meta content="Introducing Amazon SageMaker Clarify part 2   Model explainability   AWS re  Invent 2020 - Following up on part 1 (https://youtu.be/jvcPZmnXaxo), I show how you to use the model explainability capability in Amazon SageMaker Clarify, using SHAP values ..." name="twitter:description"/><link href="https://www.julien.org/youtube/2020/20201208_Introducing_Amazon_SageMaker_Clarify_part_2_-_Model_explainability_-_AWS_re_-Invent_2020.html" rel="canonical"/><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Introducing Amazon SageMaker Clarify part 2   Model explainability   AWS re  Invent 2020 - Julien Simon</title>

<!-- Umami Analytics -->
<script defer src="https://cloud.umami.is/script.js" data-website-id="27550dad-d418-4f5d-ad1b-dab573da1020"></script>
<link rel="dns-prefetch" href="//cloud.umami.is">
<style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 2.2em;
        }
        .date {
            color: #7f8c8d;
            font-size: 1.1em;
            margin-bottom: 30px;
            font-weight: 500;
        }
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin-bottom: 30px;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
            border-radius: 8px;
        }
        .description {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .description a {
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }
        .description a:hover {
            color: #2980b9;
            text-decoration: underline;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .transcript h2 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tags {
            margin-bottom: 30px;
        }
        .tags h2 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tag {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 6px 12px;
            margin: 4px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }
        .links {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .link {
            display: inline-block;
            padding: 12px 24px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.3s;
        }
        .link:hover {
            background: #2980b9;
        }
        .link.youtube {
            background: #e74c3c;
        }
        .link.youtube:hover {
            background: #c0392b;
        }
        @media (max-width: 600px) {
            .container {
                padding: 20px;
                margin: 10px;
            }
            h1 {
                font-size: 1.8em;
            }
            .links {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
<div class="container">
<h1>Introducing Amazon SageMaker Clarify part 2   Model explainability   AWS re  Invent 2020</h1>
<div class="date">December 08, 2020</div>
<div class="video-container">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" src="https://www.youtube.com/embed/1IGMG_c280E">
</iframe>
</div>
<div class="description">Following up on part 1 (<a href="https://youtu.be/jvcPZmnXaxo)," rel="noopener noreferrer" target="_blank">https://youtu.be/jvcPZmnXaxo),</a> I show how you to use the model explainability capability in Amazon SageMaker Clarify, using SHAP values computed on a credit model.

<a href="https://aws.amazon.com/sagemaker/" rel="noopener noreferrer" target="_blank">https://aws.amazon.com/sagemaker/</a>
<a href="https://aws.amazon.com/blogs/aws/new-amazon-sagemaker-clarify-detects-bias-and-increases-the-transparency-of-machine-learning-models/" rel="noopener noreferrer" target="_blank">https://aws.amazon.com/blogs/aws/new-amazon-sagemaker-clarify-detects-bias-and-increases-the-transparency-of-machine-learning-models/</a>

⭐️⭐️⭐️ Don't forget to subscribe to be notified of future episodes ⭐️⭐️⭐️

For more content:
* AWS blog: <a href="https://aws.amazon.com/blogs/aws/" rel="noopener noreferrer" target="_blank">https://aws.amazon.com/blogs/aws/</a>
* Medium blog: <a href="https://julsimon.medium.com/" rel="noopener noreferrer" target="_blank">https://julsimon.medium.com/</a>
* YouTube: <a href="https://youtube.com/juliensimonfr" rel="noopener noreferrer" target="_blank">https://youtube.com/juliensimonfr</a> 
* Podcast: <a href="http://julsimon.buzzsprout.com" rel="noopener noreferrer" target="_blank">http://julsimon.buzzsprout.com</a> 
* Twitter <a href="https://twitter.com/@julsimon" rel="noopener noreferrer" target="_blank">https://twitter.com/@julsimon</a></div>
<div class="transcript">
<h2>Transcript</h2>
            Let's move on to explainability now. If we click on model insights, we'll see feature importance, showing which features contribute most to the predicted outcome. The first one is maturity month, and these are global SHAP values for the dataset, as expected. That's pretty intuitive; the risk for the bank is different for long-term versus short-term credit.

A14, which stands for no checking account, also plays into the decision. The intuition is that without a checking account, you can't write checks, so you're not spending your money as easily. Loan amount is also interesting, as borrowing a huge sum of money versus a small sum certainly impacts the decision. A61, which indicates the amount in your savings account, is important too.

This information is available in a report that you can export. It's a notebook that you see here, showing feature importance and all the metrics we computed, both pre-training and post-training. This is useful.

Now, what if you want to understand how individual SHAP values work for each data instance? In our analysis report, we can find these metrics, which we saw in Studio. There's also the actual imbalance in the dataset. Feature importance is shown here, and we can find individual SHAP values for each data instance in S3 as an output of the analysis job. We can plot these values.

If you've seen this before, it makes sense; if not, let me explain. Here we see feature importance. Maturity month is the top one, followed by A14 (no checking account), and then loan amount. Top features are the most important, and bottom features are the least important. Each dot represents the feature value for an individual data instance, and the color indicates whether the feature value is high or low.

For example, with maturity month, all the low values have a positive contribution to the predicted output. In other words, if maturity month is low (short-term credit), the chances of credit approval increase strongly. These blue dots represent individual instances where low maturity month values increase the predicted probability, while red values generally decrease the probability.

To summarize, if individual instances have a low feature value for maturity month, the probability of credit approval increases. Conversely, a high value for maturity month decreases the probability of approval.

Let's look at loan amount. Very high values have a negative contribution to the predicted output. If you want to borrow a large sum of money, the bank is likely to say no. Smaller loan amounts are more favorable. Interestingly, some red dots suggest the bank might be interested in loaning large sums due to higher interest rates or greater profit. Generally, a high loan amount is detrimental.

You can explore this further and look at all other features. In a nutshell, SHAP values provide global insights into which features are important for the dataset and allow us to plot individual feature values to see their contributions to positive or negative outcomes.

To sum up, SageMaker Clarify allows you to compute pre-training and post-training metrics on your dataset and model. You can see various metrics in Studio, the notebook report, and S3. Feature importance is visible in Studio, and you can fetch the CSV file from S3 to plot individual feature values.

Thank you, and I'll be back soon with more videos.
        </div>
<div class="tags">
<h2>Tags</h2>
<span class="tag">Feature Importance</span><span class="tag">SHAP Values</span><span class="tag">Model Explainability</span><span class="tag">Credit Risk Analysis</span><span class="tag">SageMaker Clarify</span>
</div>
<div class="links"><a class="link" href="../../../youtube.html">← Back to YouTube Overview</a></div>
</div>
</body>
</html>
<!DOCTYPE html>

<html lang="en">
<head>
<meta content="Retail AI at the edge   Cisco Live 2025 interview - The retail landscape is rapidly evolving, with AI-driven solutions reshaping how stores operate and engage with customers. Today's consumers expect personalized..." name="description"/><meta content="Retail AI at the edge   Cisco Live 2025 interview - Julien Simon" property="og:title"/><meta content="Retail AI at the edge   Cisco Live 2025 interview - The retail landscape is rapidly evolving, with AI-driven solutions reshaping how stores operate and engage with customers. Today's consumers expect personalized..." property="og:description"/><meta content="https://www.julien.org/youtube/2025/20250701_Retail_AI_at_the_edge_-_Cisco_Live_2025_interview.html" property="og:url"/><meta content="video" property="og:type"/><meta content="summary_large_image" name="twitter:card"/><meta content="Retail AI at the edge   Cisco Live 2025 interview - Julien Simon" name="twitter:title"/><meta content="Retail AI at the edge   Cisco Live 2025 interview - The retail landscape is rapidly evolving, with AI-driven solutions reshaping how stores operate and engage with customers. Today's consumers expect personalized..." name="twitter:description"/><link href="https://www.julien.org/youtube/2025/20250701_Retail_AI_at_the_edge_-_Cisco_Live_2025_interview.html" rel="canonical"/><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Retail AI at the edge   Cisco Live 2025 interview - Julien Simon</title>
<style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 2.2em;
        }
        .date {
            color: #7f8c8d;
            font-size: 1.1em;
            margin-bottom: 30px;
            font-weight: 500;
        }
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin-bottom: 30px;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
            border-radius: 8px;
        }
        .description {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .description a {
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }
        .description a:hover {
            color: #2980b9;
            text-decoration: underline;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .transcript h2 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tags {
            margin-bottom: 30px;
        }
        .tags h2 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tag {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 6px 12px;
            margin: 4px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }
        .links {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .link {
            display: inline-block;
            padding: 12px 24px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.3s;
        }
        .link:hover {
            background: #2980b9;
        }
        .link.youtube {
            background: #e74c3c;
        }
        .link.youtube:hover {
            background: #c0392b;
        }
        @media (max-width: 600px) {
            .container {
                padding: 20px;
                margin: 10px;
            }
            h1 {
                font-size: 1.8em;
            }
            .links {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
<div class="container">
<h1>Retail AI at the edge   Cisco Live 2025 interview</h1>
<div class="date">July 01, 2025</div>
<div class="video-container">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" src="https://www.youtube.com/embed/YdPKPzgtQ00">
</iframe>
</div>
<div class="description">The retail landscape is rapidly evolving, with AI-driven solutions reshaping how stores operate and engage with customers. Today's consumers expect personalized, efficient service, while staff need immediate access to accurate information on customer traffic, inventory, sales, and other key metrics. Meeting these demands requires powerful edge computing solutions that can process and deliver insights in real time.

Powered by Intel Xeon 6 CPUs running in a Cisco UCS server, the Edge IQ Retail Assistant exemplifies this potential. This technical demonstrator will be featured in the Intel Showcase (#3035) at Cisco Live 2025, taking place in San Diego, CA, from June 8 to 12, 2025. Attendees will get a firsthand experience of how generative AI can transform retail operations without relying on GPUs.

Thanks to a chatbot interface powered by open-source small language models and real-time data analytics, store associates can interact naturally through voice or text, receiving immediate information about product availability from Chooch's inventory system or crowd density from WaitTime's analytics platform. The assistant seamlessly translates these inquiries into actionable insights, helping staff make informed decisions that enhance customer experience while optimizing store operations, all powered by CPU processing.

You can also read our blog post at <a href="https://www.arcee.ai/blog/building-an-ai-retail-assistant-at-the-edge-with-small-language-models-and-intel-xeon-cpus" rel="noopener noreferrer" target="_blank">https://www.arcee.ai/blog/building-an-ai-retail-assistant-at-the-edge-with-small-language-models-and-intel-xeon-cpus</a>

⭐️⭐️⭐️ While you're here, I’ve got a great deal for you! If you care about your online security, you need Proton Pass — the ultra-secure password manager from the creators of Proton Mail. GET 60% OFF at <a href="https://go.getproton.me/aff_c?offer_id=42&amp;aff_id=13055&amp;url_id=994" rel="noopener noreferrer" target="_blank">https://go.getproton.me/aff_c?offer_id=42&amp;aff_id=13055&amp;url_id=994</a> ⭐️⭐️⭐️</div>
<div class="transcript">
<h2>Transcript</h2>
            Welcome to the Intel QuickBytes market. We're here to talk about Arcee, a leading vendor in the small language model market. One of the challenges we hear from our customers is that they want to deploy more AI solutions in Edge and other retail locations. While it's amazing to increase productivity for their employees, there are more dashboards and different types of areas they need to look at to get a complete store status. So we partnered with Arcee, and I'm joined here with Julien Simon, chief evangelist from Arcee, to create a retail digital assistant chat that aggregates and provides real-time information to all different store managers. Julien, can you share more about who is Arcee?

Arcee is a US startup with a heavy research focus. We're a model builder. We started by improving the best open source models available on Hugging Face through our post-training stack, which is made from open source libraries like MergeKit and others. Now we're also training net new models, so new foundation models. We take those models and host them everywhere we can, from devices to edge servers to the cloud.

Awesome. And as far as the RetailIQ Digital Assistant chat, can you share more about what the solution looks like from an architecture standpoint?

Sure. Working with some of the other technology partners, let me show you the architecture. Everything is running on a Cisco server, and we've got the Chooch stack giving us inventory. You can see the products in the bins with cameras. We have the wait time system and crowd cameras. Both Chooch and wait time are exposing APIs, which are queried by our solution in the middle. We have a chatbot UI, which we'll take a look at afterwards, and a small language model optimized for Intel systems. CPUs and users can ask questions about inventory or crowd statistics, all on the same server, running on CPU.

And can you share a little bit more about the small language model as far as the size, performance, and especially how it's running on a CPU-based Xeon platform?

Yes. In this particular case, we use an 8 billion parameter small language model that we built a few months ago. It's a LAMA 3.1 variant, and when we released it, it was the best LAMA 3.1 8 billion variant available on Hugging Face. To run it on a CPU, we optimized it using the OpenVINO toolkit to quantize the model to 4-bit precision, making it smaller and more CPU-friendly without degrading it in any significant way. This optimized model runs on the CPU and performs well above 10 tokens per second, which is necessary for a good user experience. All running on Cisco unified computing systems.

Well, I know what everyone else is thinking, so can you show a quick demo of what this digital assistant chat looks like?

Sure. We see the chatbot user interface running on the server, and we can ask questions about inventory. For example, we could say, "Hey, show me potato chips in the inventory," or "Do we have Sprite in stock?" or "Show me out-of-stock products." Using the inventory information from the API, we get the appropriate data, and the small language model builds a conversation on that. The same applies to crowd statistics. We could ask, "Show me crowd stats," and pulling from the wait time API, we could see how dense the crowd is in a particular area. Of course, you can have follow-up questions because we have a language model that can maintain context. Instead of looking at information on multiple dashboards, it's all in one place, and we use human language to access it.

Can you give some other examples of store information this language model could access?

Yes, in the context of a store, we could ask about staff information. As a store manager, you could ask, "Who's the manager on duty tomorrow?" or "Who's the barista tomorrow?" or "Is that person also working the next day?" You could manage all that information. You could ask questions about kitchen equipment, such as, "Do you have any equipment issues?" assuming you have a back office system telling you if the oven is broken or the grills need maintenance. You could also access sales information by plugging into your CRM and sales systems. For example, "How many servers, how many customers did we serve yesterday?" or "What was the revenue for last week?" You could unify all those different IT systems running in your enterprise and access them at the edge in a simple, friendly way. Additionally, you could use speech-to-text and text-to-speech in the demo if you didn't want to type anything on a keyboard.

That's amazing. While we're showing this use case for retail, I assume you can use this for any other verticals or departments that need a digital assistant chat.

Sure. There are a lot of businesses that need access to information in real time, anywhere they are. Imagine civil engineering and construction, healthcare, mining, or any activity where you're out in the field and need to access systems. It's not easy to have a full-fledged laptop or system. You can just use a tablet and a mic to ask questions and connect back to your local server for immediate access without typing on a tiny keyboard. So, yes, it could apply to a ton of different use cases.

Julien, thanks for sharing. Everyone, you see the power of RetailIQ and with partners like Arcee to deliver a small language model digital chat assistant anywhere you really need it. If you want to learn more, visit intel.com/cisco.
        </div>
<div class="tags">
<h2>Tags</h2>
<span class="tag">RetailIQ</span><span class="tag">EdgeComputing</span><span class="tag">SmallLanguageModels</span><span class="tag">DigitalAssistant</span><span class="tag">RealTimeInformationAccess</span>
</div>
<div class="links"><a class="link" href="../../youtube.html">← Back to YouTube Overview</a></div>
</div>
</body>
</html>
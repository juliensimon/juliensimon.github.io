<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Build a Reasoning AI Chatbot with Arcee AI Trinity Mini Gradio OpenRouter</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 2.2em;
        }
        .date {
            color: #7f8c8d;
            font-size: 1.1em;
            margin-bottom: 30px;
            font-weight: 500;
        }
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin-bottom: 30px;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
            border-radius: 8px;
        }
        .description {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .description a {
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }
        .description a:hover {
            color: #2980b9;
            text-decoration: underline;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .transcript h2 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tags {
            margin-bottom: 30px;
        }
        .tags h2 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tag {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 6px 12px;
            margin: 4px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }
        .links {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .link {
            display: inline-block;
            padding: 12px 24px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.3s;
        }
        .link:hover {
            background: #2980b9;
        }
        .link.youtube {
            background: #e74c3c;
        }
        .link.youtube:hover {
            background: #c0392b;
        }
        @media (max-width: 600px) {
            .container {
                padding: 20px;
                margin: 10px;
            }
            h1 {
                font-size: 1.8em;
            }
            .links {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Build a Reasoning AI Chatbot with Arcee AI Trinity Mini Gradio OpenRouter</h1>
        <div class="date">December 22, 2025</div>

        <div class="video-container">
            <iframe src="https://www.youtube.com/embed/x-xzoeS3mr8"
                    allowfullscreen
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture">
            </iframe>
        </div>

        <div class="description">Watch me vibe code a chatbot with the @ArceeAI  Trinity Mini model. Perfect for developers interested in reasoning models, AI transparency, and building interactive AI demos!

Using Arcee AI’s Trinity Mini model, I created a dual-panel interface in which the reasoning process is displayed in real time above the chat response. This makes the AI’s decision-making transparent—you can watch it work through problems step by step before it delivers the final answer.

The implementation uses Gradio 6.x for the web interface, OpenRouter API for model access, and streaming support for real-time responses. Built entirely with Cursor in Plan and Build Modes and Claude Code, the project demonstrates how modern AI development tools can accelerate the development of transparent AI applications. Features include token limit controls, conversation history, and sample prompts for exploring the model’s capabilities. It’s a practical example of making AI reasoning visible and understandable.

Resources
➡️ Blog post: <a href="https://www.arcee.ai/blog/the-trinity-manifesto" target="_blank" rel="noopener noreferrer">https://www.arcee.ai/blog/the-trinity-manifesto</a>
➡️ Hugging Face model page: <a href="https://huggingface.co/arcee-ai/Trinity-Mini" target="_blank" rel="noopener noreferrer">https://huggingface.co/arcee-ai/Trinity-Mini</a>
➡️ OpenRouter mode page: <a href="https://openrouter.ai/arcee-ai/trinity-mini:free" target="_blank" rel="noopener noreferrer">https://openrouter.ai/arcee-ai/trinity-mini:free</a>

#AI #MachineLearning #Chatbot #ArceeAI #TrinityMini #Gradio #Python #OpenRouter #ReasoningAI #AIDemo #CodingTutorial #Cursor #ClaudeCode</div>

        <div class="transcript">
            <h2>Transcript</h2>
            Hi, everybody. Julian here. In this video, we're going to continue exploring the recently launched Arcee AI Trinity Mini model. And to do that, we're going to Vibecode a simple chatbot. And I'm going to use Python, Gradio, the OpenAI API. We're going to invoke the model hosted on OpenRouter. And of course, I'm going to use my favorite tools,  cursor and cloud code. Okay, let's get started. I discussed Trinity Mini in detail last time, so I'm not going to do that again. I'll just include all the links in the video description. Okay, so elevator pitch, 26 billion parameter model, mixture of experts, reasoning capabilities, and we'll see those in action. Okay, the model  is available on Hugging Face under an Apache 2.0 license, which means you can use it even for commercial apps. And that's what we're going to use today. It's also available on OpenRouter with a friendly OpenAI compatible API. OK. All right. Let's get started. Let's fire up cursor. OK. So there isn't much here, just an environment.  environment and a.on file with the open router API key, which is the usual way to do that instead of hard coding it into your code. But then again, I'm showing it on screen, which is not what you should do. And obviously, I will disable that key when I'm done. So let's just prompt  the model I'm going to use plan mode for now and just let them, yeah, just let Curator start to build the right model. So here's my prompt. I want to build a simple chatbot based on the Arcee AI Trinity mini model. You should use Gradio, the OpenAI client, and streaming mode. I also want to see the reasoning code, add some simple prompts, and then I give it the,  the model page on open router and point it at the API key. Okay. Let's try this. We'll look at the plan first and if we like the plan, then we'll switch to building. Ah, there's a question. How would you like to display the reasoning code in a separate panel tab below in line  or as a collapsible section. OK, that's a good idea. OK, show me the reasoning code on top, then the answer below. Use panels.  That's why I like to ask the models, ask me for clarification instead of just picking one of the options and then me realizing, okay, no, that's not what I wanted. Okay, so it looks like we have our plan. Let's take a look at the plan. Okay, create.  Chatbot, Gradio, OpenAI Streaming Handler, implement reasoning extraction, add sample prompts. The layout, panels are stacked vertically, sample prompts.  Okay, well that looks fairly straightforward. Okay, let's go build. So that's probably going to take a minute, so I'll pause the video and if there's anything fascinating, I'll show you. Here's the code already. Okay, so we've made good progress.  have the basic structure we have history management which is nice because I didn't ask about that so you should be able to ask follow-up questions we have the the streaming code we have sample prompts and then we have the app and the radio interface being built  All right, that should be done soon. OK, so now we have extraction for the reasoning code, which is important. And yeah, that should be the last thing. It's fixing something somehow, which is fine. I don't have to fix it.  Let's give it a minute. OK, so now we have the code. One thing I think we're missing is the requirements file. So let's ask for that. I didn't specify.  OK, done. So let's just keep all those updates. And let's just run the chatbot. OK, there's a small error. Fine. Yeah, let's ask it to review the code.  for Gradio 6 compatibility because that's the one it installed by default. I didn't specify any version here. So yeah, if there are some additional keywords or inconsistencies, let's double check that. We should save on debug. Okay, so apparently it did fix a few things. So let's keep all of those and run.  OK, let's try and run it. I don't like the built-in browser so much. OK, good, good, good. Reasoning code, chat. OK, examples. Let's give it a shot. Ooh, yes.  Man, this is fast. In the previous video, I showed you how fast this was. It was like 250 tokens per second, and we get that here. Okay, so we see the reasoning code, and that's nice. And then we see the answer.  With a bit of math and everything I like here, a bit of code. Good. Nice, nice. Why don't we try another one? What are the key differences between supervised and unsupervised learning? Let's go.  Wow. Isn't that cool? Seriously? That's the beauty of those mixture of experts models. So it's 26 billion parameters, but it's only 3 billion active, meaning when you run inference, your own  only using, you're only computing, so to speak, with 3 billion parameters. So that's why you get that kind of speed. Literally, you get the speed of a 3B model with the knowledge of a 26B model. Yeah, so that's super nice. One thing I'd love to have here is maybe the ability to set the number of  So why don't we go back to cursor and ask for that? OK. So why about let's try this. Add a slider to control the number of generated tokens. OK. Yeah.  Yeah, we can build that directly. It should be a big thing. It's just one more widget in the UI. So what did it change here? OK, yeah. It's passing a max tokens to the chat function. And what's this bit? OK.  Yeah, it's passing the same to the completion API and open router. It's adding the slider. Max 2K. Yeah, let's make that 4K maybe. And yeah, then it's passing it again.  Okay, well, that looks good. Let's run that again. I reload it. Ah, here's my slider. Okay, well, let's ask 4K. And let's try, yeah. Let's try this one again. Why not?  Yeah. All right. That's pretty cool. You could keep playing with this, right? It's so easy. Maybe one last thing I want to show you.  And one thing I tend to do, let's shut this guy down for a second, is run a code review with a different model. And we could use Claude here. And there's an extension for Claude code in cursor. So you get the best of both worlds. You get all the.  You got all the cool models here, right? And you get to use your CLI. So let's check which one we have here. Let's use Opus. OK, do code review. List issues don't fix.  Oops, don't fix them for now. And trust me, it will always, always find something. It's pretty crazy.  No error handling for missing API key. OK, that's a problem. No error handling for API calls. Oh, that's bad. Global client initialization. OK, hard-coded magic numbers for tag parsing. Oh, that's ugly. Redundant variable. All right. Oh.  there's a lot of stuff wrong about this thing. Critical issues, logic issues, ah, doc strings, oh my god, 15 issues. Ah, there you go, vibe coding. Okay, let's fix the critical issues. I advise you to fix them, I would say, one  by one or not all at once. If you ask it to fix 15, it's going to rewrite everything, and it's going to break a lot of things. And I like to tell it, apply the smallest possible change. OK.  Okay. So if API key is missing, just yes.  at the user yes I like that one I don't think it's gonna break anything right because that's the thing code reviews automated code reviews and it have this tendency to just rewrite everything and you know they can just kill kill everything you've done so far  So what is it doing here? Oh, it's going to add a try accept block around the API call, which isn't changed. Yeah, okay. I like this one too. Okay, great.  So that's a good start. And we could keep going, right? We could list the remaining issues. One thing I like to do is for a real project, not a toy demo like this, is to ask it to create GitHub issues automatically of a bunch of agents.  which live in a terminal, which is way too tiny to see. Oh, there you go. So I have a GitHub issue creator. I have a GitHub issue resolver, et cetera, et cetera. And those are really nice because you can use the GitHub CLI to get things done and focus the agent on a particular thing.  And that's really nice instead of using everything in the same conversation. So that's pretty cool. So should we try the chatbot again? Just see if we haven't broken anything. I'd be surprised, but you never know. OK, it's still working. OK, let's try one of them again. Just bump this.  All right, and off it goes. Perfect. Perfect. So as you can see, you got to use the right tool for the job. And the coding assistants are absolutely amazing. I love the combination of the built-in models in cursor and  cloud as well. Do the building first, check out the code, run it, get it to a decent place, and then use cloud code and maybe your subagents to polish everything from security to maybe the UI, maybe creating issues.  et cetera, et cetera. And working with different models will, you know, cover more ground and, you know, hopefully find more issues. Right. And, and when it comes to, to solving, you know, business problems, I think working with a high quality model like this one is just mind blowing. Right. The, the, the speed, as you can see, it's just amazing. And,  and it's super easy to use, right? You can use the, again, the OpenAI API from OpenRouter. It will look exactly like any of the other models you're working with, except, of course, the speed and the cost is very, very different. Here we're using the free version, but if we look at which has  as some kind of quota, I suppose. But if we look at the paid version, you're only paying 15 cents per million output token, which is, I think, at least 10 times cheaper than GPT-5 Mini, which is already fairly cost-effective. So if you're looking at the GPT-5s or the huge Anthropic models,  you can probably divide your cost by 50, maybe 100 if you work with a model like this. And again, it's a reasoning model. It's incredibly good. You'll see the benchmarks in the blog post. So yeah, I would recommend that you take a look. You could get a lot of speed up, a lot of scalability, and a lot of speed up.  a lot of savings, right? So what's not to like? Okay, that's what I wanted to show you today. A little bit of Vype coding, a little bit of AI-assisted software development with large models to build a simple and fast and cost-effective application with a much smaller model.  so thank you for watching i hope you liked it and i'll see you soon with more content until next time you know what to do keep rocking


        </div>

        <div class="tags">
            <h2>Tags</h2>
            <span class="tag">AI</span><span class="tag">Machine Learning</span><span class="tag">Technology</span>
        </div>

        <div class="links">
            
        </div>
    </div>
</body>
</html>

<!DOCTYPE html>

<html lang="en">
<head>
<meta content="Phi 2 on Intel Meteor Lake   Physics question - What if we could run state-of-the-art open-source LLMs on a typical personal computer? Did you think it was a lost cause? Well, it's not!

In this post, thanks ..." name="description"/><meta content="Phi 2 on Intel Meteor Lake   Physics question - Julien Simon" property="og:title"/><meta content="Phi 2 on Intel Meteor Lake   Physics question - What if we could run state-of-the-art open-source LLMs on a typical personal computer? Did you think it was a lost cause? Well, it's not!

In this post, thanks ..." property="og:description"/><meta content="https://www.julien.org/youtube/2024/20240320_Phi-2_on_Intel_Meteor_Lake_-_Physics_question.html" property="og:url"/><meta content="video" property="og:type"/><meta content="summary_large_image" name="twitter:card"/><meta content="Phi 2 on Intel Meteor Lake   Physics question - Julien Simon" name="twitter:title"/><meta content="Phi 2 on Intel Meteor Lake   Physics question - What if we could run state-of-the-art open-source LLMs on a typical personal computer? Did you think it was a lost cause? Well, it's not!

In this post, thanks ..." name="twitter:description"/><link href="https://www.julien.org/youtube/2024/20240320_Phi-2_on_Intel_Meteor_Lake_-_Physics_question.html" rel="canonical"/><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>
<!-- Umami Analytics -->
<script defer src="https://cloud.umami.is/script.js" data-website-id="27550dad-d418-4f5d-ad1b-dab573da1020"></script>
<link rel="dns-prefetch" href="//cloud.umami.is">Phi 2 on Intel Meteor Lake   Physics question - Julien Simon</title>
<style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 2.2em;
        }
        .date {
            color: #7f8c8d;
            font-size: 1.1em;
            margin-bottom: 30px;
            font-weight: 500;
        }
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin-bottom: 30px;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
            border-radius: 8px;
        }
        .description {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .description a {
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }
        .description a:hover {
            color: #2980b9;
            text-decoration: underline;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .transcript h2 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tags {
            margin-bottom: 30px;
        }
        .tags h2 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tag {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 6px 12px;
            margin: 4px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }
        .links {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .link {
            display: inline-block;
            padding: 12px 24px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.3s;
        }
        .link:hover {
            background: #2980b9;
        }
        .link.youtube {
            background: #e74c3c;
        }
        .link.youtube:hover {
            background: #c0392b;
        }
        @media (max-width: 600px) {
            .container {
                padding: 20px;
                margin: 10px;
            }
            h1 {
                font-size: 1.8em;
            }
            .links {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
<div class="container">
<h1>Phi 2 on Intel Meteor Lake   Physics question</h1>
<div class="date">March 20, 2024</div>
<div class="video-container">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" src="https://www.youtube.com/embed/nTNYRDORq14">
</iframe>
</div>
<div class="description">What if we could run state-of-the-art open-source LLMs on a typical personal computer? Did you think it was a lost cause? Well, it's not!

In this post, thanks to the Hugging Face Optimum library, we apply 4-bit quantization to the 2.7-billion Microsoft Phi-2 model, and we run inference on a mid-range laptop powered by an Intel Meteor Lake CPU.

More in the blog post: "A chatbot on your laptop" <a href="https://huggingface.co/blog/phi2-intel-meteor-lake" rel="noopener noreferrer" target="_blank">https://huggingface.co/blog/phi2-intel-meteor-lake</a></div>
<div class="transcript">
<h2>Transcript</h2>
            you

Cleaned transcript:

You

Julien from Arcee introduced the new Arcee Maestro platform, which is designed to streamline the development and deployment of AI models. The platform offers a user-friendly interface and robust tools for data preprocessing, model training, and performance monitoring.

The integration of Qwen, the large language model from Alibaba Cloud, significantly enhances the capabilities of Arcee Maestro. Qwen provides advanced natural language processing, enabling more sophisticated applications in areas such as customer service, content creation, and data analysis.

Julien also highlighted the importance of DeepSeek, a powerful search and recommendation engine, in complementing the functionalities of Arcee Maestro. Together, these tools create a comprehensive ecosystem for businesses looking to leverage AI technologies effectively.

Participants were impressed by the demo, which showcased the seamless workflow from data ingestion to model deployment. The feedback was overwhelmingly positive, with many expressing interest in adopting Arcee Maestro for their projects.
        </div>
<div class="tags">
<h2>Tags</h2>
<span class="tag">AI Development</span><span class="tag">Model Deployment</span><span class="tag">Natural Language Processing</span><span class="tag">AI Ecosystem</span><span class="tag">Data Preprocessing</span>
</div>
<div class="links"><a class="link" href="../../../youtube.html">‚Üê Back to YouTube Overview</a></div>
</div>
</body>
</html>
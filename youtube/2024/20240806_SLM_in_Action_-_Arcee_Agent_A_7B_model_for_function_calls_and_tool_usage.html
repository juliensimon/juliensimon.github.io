<!DOCTYPE html>

<html lang="en">
<head>
<meta content="SLM in Action   Arcee Agent A 7B model for function calls and tool usage - In this video, you will learn about Arcee Agent, a new state-of-the-art 7-billion parameter model created by Arcee.ai from Qwen2-7B. 

⭐️⭐️⭐️ Don't forget to su..." name="description"/><meta content="SLM in Action   Arcee Agent A 7B model for function calls and tool usage - Julien Simon" property="og:title"/><meta content="SLM in Action   Arcee Agent A 7B model for function calls and tool usage - In this video, you will learn about Arcee Agent, a new state-of-the-art 7-billion parameter model created by Arcee.ai from Qwen2-7B. 

⭐️⭐️⭐️ Don't forget to su..." property="og:description"/><meta content="https://www.julien.org/youtube/2024/20240806_SLM_in_Action_-_Arcee_Agent_A_7B_model_for_function_calls_and_tool_usage.html" property="og:url"/><meta content="video" property="og:type"/><meta content="summary_large_image" name="twitter:card"/><meta content="SLM in Action   Arcee Agent A 7B model for function calls and tool usage - Julien Simon" name="twitter:title"/><meta content="SLM in Action   Arcee Agent A 7B model for function calls and tool usage - In this video, you will learn about Arcee Agent, a new state-of-the-art 7-billion parameter model created by Arcee.ai from Qwen2-7B. 

⭐️⭐️⭐️ Don't forget to su..." name="twitter:description"/><link href="https://www.julien.org/youtube/2024/20240806_SLM_in_Action_-_Arcee_Agent_A_7B_model_for_function_calls_and_tool_usage.html" rel="canonical"/><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>SLM in Action   Arcee Agent A 7B model for function calls and tool usage - Julien Simon</title>
<style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 2.2em;
        }
        .date {
            color: #7f8c8d;
            font-size: 1.1em;
            margin-bottom: 30px;
            font-weight: 500;
        }
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin-bottom: 30px;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
            border-radius: 8px;
        }
        .description {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .description a {
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }
        .description a:hover {
            color: #2980b9;
            text-decoration: underline;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .transcript h2 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tags {
            margin-bottom: 30px;
        }
        .tags h2 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tag {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 6px 12px;
            margin: 4px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }
        .links {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .link {
            display: inline-block;
            padding: 12px 24px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.3s;
        }
        .link:hover {
            background: #2980b9;
        }
        .link.youtube {
            background: #e74c3c;
        }
        .link.youtube:hover {
            background: #c0392b;
        }
        @media (max-width: 600px) {
            .container {
                padding: 20px;
                margin: 10px;
            }
            h1 {
                font-size: 1.8em;
            }
            .links {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
<div class="container">
<h1>SLM in Action   Arcee Agent A 7B model for function calls and tool usage</h1>
<div class="date">August 06, 2024</div>
<div class="video-container">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" src="https://www.youtube.com/embed/igEq0yXDbQ8">
</iframe>
</div>
<div class="description">In this video, you will learn about Arcee Agent, a new state-of-the-art 7-billion parameter model created by Arcee.ai from Qwen2-7B. 

⭐️⭐️⭐️ Don't forget to subscribe to be notified of future videos. Follow me on Medium at <a href="https://julsimon.medium.com" rel="noopener noreferrer" target="_blank">https://julsimon.medium.com</a> or Substack at <a href="https://julsimon.substack.com." rel="noopener noreferrer" target="_blank">https://julsimon.substack.com.</a> ⭐️⭐️⭐️

At the time of recording, Arcee Agent is one of the top models for function calls and tool usage, outperforming GPT-3.5 and current versions of GPT-4o.

Arcee Agent was built on Arcee Cloud and you can learn more at <a href="https://www.arcee.ai/product/arceecloud." rel="noopener noreferrer" target="_blank">https://www.arcee.ai/product/arceecloud.</a>

Here, I run the full precision model on my M3 MacBook and ollama to build a financial agent able to invoke the Yahoo Finance API to answer questions on listed companies: what's the stock price? Who's the CEO? What is this company doing? and more.

Along the way, I also show you that you don't need Github Copilot to explain code and generate documentation. You can use Arcee-Spark locally instead!

* Blog post: <a href="https://blog.arcee.ai/introducing-arcee-agent-a-specialized-7b-language-model-for-function-calling-and-tool-use-2/" rel="noopener noreferrer" target="_blank">https://blog.arcee.ai/introducing-arcee-agent-a-specialized-7b-language-model-for-function-calling-and-tool-use-2/</a>
* Model page: <a href="https://huggingface.co/arcee-ai/Arcee-Agent" rel="noopener noreferrer" target="_blank">https://huggingface.co/arcee-ai/Arcee-Agent</a>
* Notebook: <a href="https://gitlab.com/juliensimon/arcee-demos/-/blob/main/arcee-agent/yahoo_finance_assistant.ipynb" rel="noopener noreferrer" target="_blank">https://gitlab.com/juliensimon/arcee-demos/-/blob/main/arcee-agent/yahoo_finance_assistant.ipynb</a>
<a href="https://www.youtube.com/watch?v=igEq0yXDbQ8&amp;t=0" rel="noopener noreferrer" target="_blank">00:00</a> Introduction
<a href="https://www.youtube.com/watch?v=igEq0yXDbQ8&amp;t=44" rel="noopener noreferrer" target="_blank">00:44</a> Introducing Arcee-Agent
<a href="https://www.youtube.com/watch?v=igEq0yXDbQ8&amp;t=115" rel="noopener noreferrer" target="_blank">01:55</a> Running Arcee-Agent locally with ollama
<a href="https://www.youtube.com/watch?v=igEq0yXDbQ8&amp;t=180" rel="noopener noreferrer" target="_blank">03:00</a> Looking at the four functions implemented by our financial agent
<a href="https://www.youtube.com/watch?v=igEq0yXDbQ8&amp;t=410" rel="noopener noreferrer" target="_blank">06:50</a> Routing user queries to the appropriate function
<a href="https://www.youtube.com/watch?v=igEq0yXDbQ8&amp;t=505" rel="noopener noreferrer" target="_blank">08:25</a> Explaining and documenting our code with Arcee-Spark
<a href="https://www.youtube.com/watch?v=igEq0yXDbQ8&amp;t=602" rel="noopener noreferrer" target="_blank">10:02</a> Running inference with our financial agent

Configuration file for ollama:
FROM ./llama-spark-dpo-v0.3-Q5_K_S.gguf

#ai #aws #slm #llm #openai #chatgpt #opensource #huggingface

Sign up for Arcee Cloud at <a href="https://www.arcee.ai," rel="noopener noreferrer" target="_blank">https://www.arcee.ai,</a> and please follow Arcee.ai on LinkedIn to stay on top of the latest Small Language Model action! <a href="https://www.linkedin.com/company/99895334" rel="noopener noreferrer" target="_blank">https://www.linkedin.com/company/99895334</a></div>
<div class="transcript">
<h2>Transcript</h2>
            Hi everybody, this is Julien from Arcee. There's a lot of excitement around using agents to perform tasks that language models are not great at, such as math or generating API calls to call your own applications. Arcee recently released a model called Arcee Agent, which was specifically built for agent-based applications. In this video, I'm going to talk a little bit about Arcee Agent and what it is, and then we're going to run a demo where I use the model to generate API calls for Yahoo Finance to retrieve company information, stock quotes, etc. Let's get started.

Arcee Agent has been specifically built for function calling and using external tools. It's based on the QAN2 7 billion model, which is already a very good model, and it was further trained and specialized for agent apps. This is the blog post. Of course, I will put all the links in the video description so you can learn more about the model. It can be used for API integration, database operations, code, and more. You can also see some benchmarks showing it ranking high, outperforming GPT-3.5, a recent version of GPT-4.0, and many other models. It is a really good model, and I encourage you to try it. As you would expect, it is available on the Hugging Face Hub, so you can go and grab it there, either the full precision model or the quantized version if you prefer to run smaller versions, maybe locally.

Let's look at the demo now. In this demo, I'm going to run everything locally. I will run Arcee Agent full precision 7B with all ammo, and integrate through Langchain to run inference on this local model, using prompts to perform Python function calls to the Yahoo Finance API to retrieve stock prices, etc. We need a few dependencies for this: Langchain with the Olama integration, and the Yahoo Finance package. Let's import all of those.

Next, we need to make sure we have the model locally. I've already done this, so it should be quick. Let's verify it's there. Yes, it's 5.4 gigs. Good. We should be able to run this locally now. Let's run this cell. Good.

Now, let's look at the functions we'd like the model to perform. We have a prompt with four primary functions: checking the last price of a specified stock, finding the name of a company's CEO, finding what a company does, and answering specific questions about a company. The model should use the appropriate function based on the user query. The four functions are `getStockPrice`, `getCEOName`, `getCompanySummary`, and `answerGeneralQuestion`.

`getStockPrice` takes the name of a company. For example, "What's the last closing price of McDonald's?" The model should automatically find the stock symbol, the ticker code, and call the relevant Yahoo Finance API to return the last closing price for McDonald's, which might be $250.

`getCEOName` works similarly. I'll pass a company name, such as McDonald's, and the model should figure out the ticker code, call the appropriate Yahoo Finance API, and retrieve the name of the CEO, printing something like, "The CEO of McDonald's is [Name]."

`getCompanySummary` also follows the same pattern. I'll pass a company name, and the model should output the ticker code, call the API, extract the long summary describing the company's activities, and print that out.

The final function, `answerGeneralQuestion`, is a catch-all. If the model does not detect any of the three specific intents in the prompt, it will use this function to answer the question with its built-in knowledge.

The instructions are simple: if the user asks about a stock price, use `getStockPrice`; if about a CEO name, use `getCEOName`, etc. This is my prompt. I didn't provide a lot of examples, just a few, to keep the prompt shorter and the calls faster.

Now, let's look at how we're going to run these prompts through the model. We'll invoke the model with a function called `LLMPAC`. This function will take our input, including the system prompt and the user query, and pass it to the model. The model will return the name of the function to call, and we'll extract and run that function locally. The model will not run the function; it will return the function call, which we extract and execute.

To explain this function, let's use another model, LamaSpark, our iteration on Lama3, 1.8 billion. Let's run this and ask it to explain what the code does. Wonderful. Now we have a clear, line-by-line explanation. It's a great alternative to GitHub Copilot. If you don't want to pay for Copilot, why not use this instead? Let's improve the notebook with some documentation.

Now, let's run some examples and print out the responses, along with the API calls. "What's the stock price for Caterpillar?" The model figured out that "CAT" is the ticker code for Caterpillar, called the API, and got the job done. 

Let's try another: "Who runs Caterpillar?" This is a fuzzier question, but the model matched it to the CEO name function. Running a company generally means being the CEO, and the model extracted the information accordingly.

Next, "What does Caterpillar build?" This is a general question about the company, so the model used the `answerGeneralQuestion` function.

Finally, "Who are the main competitors of Caterpillar?" This is another general question, and the model used the `answerGeneralQuestion` function, listing a bunch of companies that seem to make sense.

Let's try another company. "What's the stock price for Tesla?" "Who runs Tesla?" The model correctly identified Elon Musk as the CEO, with his full job title as Co-Founder Techno King. "Do they have any competition?" The model listed a bunch of automakers, which makes sense.

That's pretty much what I wanted to show you in this video: the Arcee Agent model and a simple demo on using it to generate Python API calls. Keep in mind, you can do much more, such as SQL and other tasks. Keep exploring, and I'll come back to agent models in future videos. Thank you for watching, and you know what to do. Keep rocking.
        </div>
<div class="tags">
<h2>Tags</h2>
<span class="tag">Arcee Agent</span><span class="tag">API Integration</span><span class="tag">Stock Market Analysis</span><span class="tag">Machine Learning Models</span><span class="tag">Local Model Execution</span>
</div>
<div class="links"><a class="link" href="../../youtube.html">← Back to YouTube Overview</a></div>
</div>
</body>
</html>
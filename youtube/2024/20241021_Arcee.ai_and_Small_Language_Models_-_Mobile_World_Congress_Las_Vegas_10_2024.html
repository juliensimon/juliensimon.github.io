<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Arcee.ai and Small Language Models   Mobile World Congress Las Vegas 10 2024</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 2.2em;
        }
        .date {
            color: #7f8c8d;
            font-size: 1.1em;
            margin-bottom: 30px;
            font-weight: 500;
        }
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin-bottom: 30px;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
            border-radius: 8px;
        }
        .description {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .description a {
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }
        .description a:hover {
            color: #2980b9;
            text-decoration: underline;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .transcript h2 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tags {
            margin-bottom: 30px;
        }
        .tags h2 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tag {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 6px 12px;
            margin: 4px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }
        .links {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .link {
            display: inline-block;
            padding: 12px 24px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.3s;
        }
        .link:hover {
            background: #2980b9;
        }
        .link.youtube {
            background: #e74c3c;
        }
        .link.youtube:hover {
            background: #c0392b;
        }
        @media (max-width: 600px) {
            .container {
                padding: 20px;
                margin: 10px;
            }
            h1 {
                font-size: 1.8em;
            }
            .links {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Arcee.ai and Small Language Models   Mobile World Congress Las Vegas 10 2024</h1>
        <div class="date">October 21, 2024</div>
        
        <div class="video-container">
            <iframe src="https://www.youtube.com/embed/aTKEeFyJlDs" 
                    allowfullscreen 
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture">
            </iframe>
        </div>
        
        <div class="description">Talk about Small Language Models, Mobile World Congress, Las Vegas, October 2024.

⭐️⭐️⭐️ Don't forget to subscribe to be notified of future videos. Follow me on Medium at <a href="https://julsimon.medium.com" target="_blank" rel="noopener noreferrer">https://julsimon.medium.com</a> or Substack at <a href="https://julsimon.substack.com." target="_blank" rel="noopener noreferrer">https://julsimon.substack.com.</a> ⭐️⭐️⭐️</div>
        
        <div class="transcript">
            <h2>Transcript</h2>
            So my name is Julien. I work for a startup called Arcee. First time you ever hear the name, trust me, not the last. Right? And you'll remember, oh, I saw that guy in Vegas. Right? Mark my words. So what do we do? Well, we're the specialists of small language models. And I guess I will explain what those models are and why they are the future.

A lot of customers over the last two years have adopted AI, and that's great across industries, across use cases, across company sizes. Probably they've done that with closed models, right? Open AI, Anthropic, and others. And I guess that's the first step, that's fine. But then very quickly, those customers realize, well, we're really renting those models, right? We're paying per token. And why would you rent something when you can actually own it? In the case of AI models, there are a lot of benefits in owning your AI. The first one is obvious and I think it should resonate with telco customers. It's of course deploying those models on your infrastructure, which could be on-prem, cloud, private cloud, or at the edge instead of sending your data to a third-party API hosted somewhere else by someone else. So in terms of privacy for your data, your customers' data, in terms of compliance, it's an easier discussion.

Number two, and this has been a major pain point for a lot of companies, it's very, very difficult to adapt those closed models to your data and your use cases. They are Swiss Army Knives, so they work okay for a lot of different things, but when you need them to be awesome at one thing, they don't deliver. By working with models that you're tailoring to your data and use cases, you get maximum accuracy and maximum performance on whatever you're interested in, which is probably not cooking recipes, poetry, or astronomy questions.

The third benefit in owning your models is, of course, you can right-size each model to the particular problem you're trying to solve. Cost performance can be very different across use cases. If you want to build a chatbot application for millions of users every day, that's one problem. If you want to build an R&D chatbot for 100 engineers working in a lab, that's a very different problem. And if you want to deploy a model on smartphones or at the edge, that's yet another problem. So one size does not fit all. And again, those closed models only give you one size. So it works or it doesn't. Most of the time, it's somewhere in between, but you never really get what you want or hoped for. And what that means is you cannot maximize ROI. It's all about compromises. Who wants okay models? We don't want okay models. We want awesome models, we want maximum ROI, we want maximum performance. Since when was okay, okay? It's not okay.

So hopefully you haven't been living under a rock, and you haven't been swallowing AI marketing propaganda hook, line, and sinker over the last year or so. Because the open-source community has been very, very busy not only catching up to the best closed models but outperforming them. When I say outperforming, you need to understand what performance really means. Some people want you to believe performance is predicting in one millisecond, but why would I care? I don't need my chatbot to predict in one millisecond. I don't need my document processing app to predict in one millisecond. I need my app or my service to deliver maximum accuracy for the right price. It's all about cost performance. Raw performance means nothing. We're not trying to do Formula One here. We're trying to solve business problems with the right level of cost performance for each use case.

And so you can find a ton of models. The champions of open-source AI are a company called Hugging Face. Who has heard of Hugging Face? Okay. I worked for them for three years before working for Arcee. So must have done something right. You have 1 million open-source models on Hugging Face. So there's choice there. And as you can see, the gap is closing. Thanks to companies like Mistral, Meta, Google, and Microsoft, who also share some good open-source models, the gap is closing very quickly. So now you can get the same business performance with an open-source model a fraction of the size of those closed models. And you get privacy, security, compliance, tailoring capabilities, and better ROI, et cetera, et cetera.

So where do we fit? We're the open small language model leader. And that's a bold statement. I'm going to back it up. And we'll keep backing it up in the next few weeks. What do we do? We work on state-of-the-art training. We have a platform called Arcee Enterprise, which is a combination of open-source libraries like Merge Kit, Distill Kit, etc., all fascinating stuff. And also some, I would say, secret sauce and in-house training recipes. Thanks to those, we start from good models like Llama 3 or others and make them even better. We deliver to the community and to our customers best-in-class models based on open architectures. Some of our models are available on Hugging Face. This is one example, Arcee Light. It's the best 1.5 billion model available today. And when I say best, I mean based on the Hugging Face leaderboard benchmarks, which is pretty much what everybody's looking at these days. So it's the best 1.5B. That's even small for a phone. We have the best 8B model. We started from Llama 3.1 and made it even better. And just for the record, we have a 3B and a 4B that are pretty damn good, but I didn't want the slide to be too busy.

We have the best A to B model available anywhere. We have the best Arabic language model because, hey, not everybody speaks English, and Arabic and other languages are not well supported. So just to prove our point, we built the best Arabic model available anywhere. And recently, we also built a new model called Supernova, which is a 70B model. Not only is it the best 70B model available anywhere, but it's also outperforming the best closed models, and I will double-click on that. These models are great because we start from good architectures like Llama 3, Qwen, etc. So the baseline models are already pretty good. And then we apply our training stack, our fine-tuning stack, our data sets, our know-how, and a bit of secret sauce. And we make them even better. This goes to show there's still a ton of additional performance to get from those models. And keep in mind, these are still, I would say, general-purpose models. So imagine the performance you could get if you took Llama 318B or a flavor of it and fine-tuned it on customer support data or core network data. It would be massively better than anything available today.

A typical workflow looks something like this. There are many steps. You can do all those things with our libraries and our platform, and we can help you do it. Or you can do it on your own. Continuous pre-training, instruction fine-tuning, model alignment, etc., and more radical techniques like model merging, which is really a game changer. If it's the first time you hear about model merging, I would encourage you to read more about it. It's basically a technique where there is no training at all. You take several models that have the properties you're looking for. Let's say one has some baseline telco knowledge, another one has some baseline IoT knowledge, and you can literally merge them from a mathematical operation, so averaging out their weights, no training involved. I can run it on my laptop in 10 minutes, no GPU, etc. Model merging is making model adaptation much simpler, much faster, and much cheaper too.

So when we apply that training stack, we build a model like Supernova. You can all try it. This is the slide you want to take a picture of because after the session, you definitely want to go to supernova.arcee.ai and check that the proof is in the pudding. And of course, you can get in touch with us if you want to know more. Supernova is a 70 billion model that we built. It's not only better than Llama 370 billion, but it's also better than Llama 3405 billion. It's also better than GPT-40 and Claude 3.5 Sonnet on this IF eval benchmark and others. So you don't have to believe me. Go and try it. Go read our blog. Figure it out. But you will see how easily you can outperform those closed, expensive models with much more cost-effective and higher-performance models like Supernova.

Our mission is to buy out closed models. We're taking customers off Open AI and Anthropic every day, saving them from the spend and, I guess, the privacy issues they may be afraid of. So I can only encourage you to read more about us. AI is changing everything. Don't doubt it. We've barely scratched the surface. So if you believe that AI is changing the world, changing your business, then how can you not own it? Right? So please don't rent it. That's us, Arcee. This is me, Julien at Arcee. Thank you very much for inviting me, and get in touch later if you have questions. Thank you so much.


        </div>
        
        <div class="tags">
            <h2>Tags</h2>
            <span class="tag">Open-Source AI</span><span class="tag">Small Language Models</span><span class="tag">AI Model Optimization</span><span class="tag">Cost-Effective AI Solutions</span><span class="tag">Privacy and Compliance in AI</span>
        </div>
        
        <div class="links">
            <a href="https://www.julien.org/youtube.html" class="link">Julien.org - Youtube</a>
            <a href="https://youtube.com/@juliensimon.fr" class="link youtube">Julien's YouTube channel</a>
        </div>
    </div>
</body>
</html>
<!DOCTYPE html>

<html lang="en">
<head>
<meta content="Arcee.ai and Small Language Models   Mobile World Congress Las Vegas 10 2024 - Talk about Small Language Models, Mobile World Congress, Las Vegas, October 2024.

⭐️⭐️⭐️ Don't forget to subscribe to be notified of future videos. Follow me o..." name="description"/><meta content="Arcee.ai and Small Language Models   Mobile World Congress Las Vegas 10 2024 - Julien Simon" property="og:title"/><meta content="Arcee.ai and Small Language Models   Mobile World Congress Las Vegas 10 2024 - Talk about Small Language Models, Mobile World Congress, Las Vegas, October 2024.

⭐️⭐️⭐️ Don't forget to subscribe to be notified of future videos. Follow me o..." property="og:description"/><meta content="https://www.julien.org/youtube/2024/20241021_Arcee.ai_and_Small_Language_Models_-_Mobile_World_Congress_Las_Vegas_10_2024.html" property="og:url"/><meta content="video" property="og:type"/><meta content="summary_large_image" name="twitter:card"/><meta content="Arcee.ai and Small Language Models   Mobile World Congress Las Vegas 10 2024 - Julien Simon" name="twitter:title"/><meta content="Arcee.ai and Small Language Models   Mobile World Congress Las Vegas 10 2024 - Talk about Small Language Models, Mobile World Congress, Las Vegas, October 2024.

⭐️⭐️⭐️ Don't forget to subscribe to be notified of future videos. Follow me o..." name="twitter:description"/><link href="https://www.julien.org/youtube/2024/20241021_Arcee.ai_and_Small_Language_Models_-_Mobile_World_Congress_Las_Vegas_10_2024.html" rel="canonical"/><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Arcee.ai and Small Language Models   Mobile World Congress Las Vegas 10 2024 - Julien Simon</title>
<style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 2.2em;
        }
        .date {
            color: #7f8c8d;
            font-size: 1.1em;
            margin-bottom: 30px;
            font-weight: 500;
        }
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin-bottom: 30px;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
            border-radius: 8px;
        }
        .description {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .description a {
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }
        .description a:hover {
            color: #2980b9;
            text-decoration: underline;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            white-space: pre-wrap;
            font-size: 1em;
        }
        .transcript h2 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tags {
            margin-bottom: 30px;
        }
        .tags h2 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        .tag {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 6px 12px;
            margin: 4px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }
        .links {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .link {
            display: inline-block;
            padding: 12px 24px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background-color 0.3s;
        }
        .link:hover {
            background: #2980b9;
        }
        .link.youtube {
            background: #e74c3c;
        }
        .link.youtube:hover {
            background: #c0392b;
        }
        @media (max-width: 600px) {
            .container {
                padding: 20px;
                margin: 10px;
            }
            h1 {
                font-size: 1.8em;
            }
            .links {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
<div class="container">
<h1>Arcee.ai and Small Language Models   Mobile World Congress Las Vegas 10 2024</h1>
<div class="date">October 21, 2024</div>
<div class="video-container">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" src="https://www.youtube.com/embed/aTKEeFyJlDs">
</iframe>
</div>
<div class="description">Talk about Small Language Models, Mobile World Congress, Las Vegas, October 2024.

⭐️⭐️⭐️ Don't forget to subscribe to be notified of future videos. Follow me on Medium at <a href="https://julsimon.medium.com" rel="noopener noreferrer" target="_blank">https://julsimon.medium.com</a> or Substack at <a href="https://julsimon.substack.com." rel="noopener noreferrer" target="_blank">https://julsimon.substack.com.</a> ⭐️⭐️⭐️</div>
<div class="transcript">
<h2>Transcript</h2>
            My name is Julien. I work for a startup called Arcee. First time you ever hear the name, trust me, not the last. And you'll remember, oh, I saw that guy in Vegas. Mark my words. 

So, what do we do? We're the specialists of small language models. I will explain what those models are and why they are the future. A lot of customers over the last two years have adopted AI, which is great across industries, use cases, and company sizes. They've done this with closed models, such as OpenAI, Anthropic, and others. That's the first step, and it's fine. But then, very quickly, those customers realize they're renting those models, paying per token. Why would you rent something when you can own it? In the case of AI models, there are many benefits to owning your AI.

First, deploying those models on your infrastructure—on-prem, cloud, private cloud, or at the edge—instead of sending your data to a third-party API hosted elsewhere, enhances privacy and compliance for your data and your customers' data. 

Second, adapting closed models to your specific data and use cases is very difficult. These models are like Swiss Army Knives; they work okay for many things but aren't awesome at one specific task. By tailoring models to your data and use cases, you get maximum accuracy and performance for what you need, which is probably not cooking recipes, poetry, or astronomy questions.

Third, owning your models allows you to right-size each model to the particular problem you're trying to solve. Cost and performance can vary widely across use cases. Building a chatbot for millions of users daily is one problem; building an R&amp;D chatbot for 100 engineers in a lab is another. Deploying a model on smartphones or at the edge is yet another. One size does not fit all, and closed models only give you one size, which often means compromises and suboptimal ROI.

Hopefully, you haven't been living under a rock or swallowing AI marketing propaganda. The open-source community has been very busy, not only catching up to the best closed models but outperforming them. Performance isn't just about raw speed; it's about delivering maximum accuracy for the right price. We're solving business problems with the right level of cost performance for each use case.

There are a ton of models available. Hugging Face, a leader in open-source AI, hosts over a million models. The gap between open-source and closed models is closing quickly, thanks to companies like Mistral, Meta, Google, and Microsoft. You can now get the same business performance with an open-source model that is a fraction of the size of closed models, with better privacy, security, compliance, tailoring capabilities, and ROI.

Where do we fit? We're the open small language model leader. We work on state-of-the-art training with our platform, Arcee Enterprise, which combines open-source libraries like MergeKit, DistillKit, and our in-house training recipes. We start with good models like Llama 3 and make them even better. We deliver best-in-class models based on open architectures. Some of our models are available on Hugging Face, like Arcee Light, the best 1.5 billion parameter model available today, based on Hugging Face leaderboard benchmarks. We also have the best 8 billion parameter model, starting from Llama 3.1 and making it even better. We have 3 billion and 4 billion parameter models that are also very good.

We have the best Arabic language model because not everyone speaks English, and other languages are not well-supported. Recently, we built a new model called Supernova, a 70 billion parameter model that outperforms the best closed models. These models are great because we start with good architectures like Llama 3 and apply our training stack, fine-tuning stack, datasets, and know-how to make them even better. There's still a lot of additional performance to gain from these models. Imagine the performance you could get by fine-tuning Llama 3 on customer support or core network data.

A typical workflow involves continuous pre-training, instruction fine-tuning, model alignment, and more radical techniques like model merging. Model merging is a game-changer. It involves no training; you take several models with the properties you need, merge them mathematically, and average out their weights. This can be done on a laptop in 10 minutes without a GPU. Model merging makes model adaptation simpler, faster, and cheaper.

When we apply our training stack, we build models like Supernova. You can try it at supernova.arcee.ai. It's better than Llama 3 70 billion, Llama 3 40 billion, GPT-4, and Claude 3.5 on the IF eval benchmark and others. Don't just take my word for it; try it out, read our blog, and see for yourself how easily you can outperform closed, expensive models with more cost-effective and higher-performance models like Supernova.

Our mission is to move customers away from closed models, saving them money and addressing privacy concerns. AI is changing everything, and we've barely scratched the surface. If you believe AI is changing the world and your business, why wouldn't you own it? Don't rent it. That's us, Arcee. This is me, Julien at Arcee. Thank you for inviting me, and feel free to get in touch if you have questions. Thank you.
        </div>
<div class="tags">
<h2>Tags</h2>
<span class="tag">Open-source AI</span><span class="tag">Small language models</span><span class="tag">AI ownership benefits</span><span class="tag">Model customization</span><span class="tag">Privacy and compliance</span>
</div>
<div class="links"><a class="link" href="../../../youtube.html">← Back to YouTube Overview</a></div>
</div>
</body>
</html>